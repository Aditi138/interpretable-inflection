{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang='italian'\n",
    "exp_dir='/mnt/conll/exp-data'\n",
    "bpe_n=1000\n",
    "batch_size=4\n",
    "beam_size=1\n",
    "#gold\n",
    "gold_file='{}/{}/{}-dev'.format(exp_dir,lang,lang)\n",
    "\n",
    "\n",
    "def print_errors(pred_file, gold_file):\n",
    "    pred_f=open(pred_file)\n",
    "    gold_f=open(gold_file)\n",
    "    for i,(pred_line,gold_line) in enumerate(zip(pred_f,gold_f)):\n",
    "    #if i==0:\n",
    "        lemma, infl, msd = pred_line.strip().split('\\t')\n",
    "        _, infl_g, _ = gold_line.strip().split('\\t')\n",
    "        if infl!=infl_g:\n",
    "            print(lemma, infl_g, msd, infl)\n",
    "        #print(lemma, infl, msd, infl_g, infl==infl_g)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# unscaled alignments scaled with gate \n",
    "def unscaled_al_heatmap(attn_data,ind):\n",
    "    # input data\n",
    "    src = attn_data[ind]['src']\n",
    "    trg = attn_data[ind]['pred']\n",
    "    msd = attn_data[ind]['inflection']\n",
    "    gate_v = attn_data[ind]['attn']['gate']\n",
    "    l_v = attn_data[ind]['attn']['lemma']\n",
    "    f_v = attn_data[ind]['attn']['inflection']\n",
    "\n",
    "    all_al=torch.cat((l_v,gate_v,f_v), dim=1)\n",
    "    all_src = src + ['lemma', 'msd']+ msd\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    r = sns.heatmap(all_al, cmap='BuPu',cbar=False,xticklabels=all_src,yticklabels=trg)\n",
    "    r.set_yticklabels(r.get_yticklabels(), rotation=0)\n",
    "    r.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = True, labeltop=True)\n",
    "    r.set_title(\"Heatmap: Unscaled alignments and gate\")\n",
    "    return\n",
    "\n",
    "# unscaled alignments scaled with gate\n",
    "def scaled_al_heatmap(attn_data,ind,save_file=None):\n",
    "    # input data\n",
    "    src = attn_data[ind]['src']\n",
    "    trg = attn_data[ind]['pred']\n",
    "    msd = attn_data[ind]['inflection']\n",
    "    gate_v = attn_data[ind]['attn']['gate']\n",
    "    l_v = attn_data[ind]['attn']['lemma']\n",
    "    f_v = attn_data[ind]['attn']['inflection']\n",
    "\n",
    "    lemma_weights = gate_v[:, 0].unsqueeze(1)\n",
    "    infl_weights = gate_v[:, 1].unsqueeze(1)\n",
    "\n",
    "    al_l_scaled = l_v * lemma_weights\n",
    "    al_f_scaled = f_v * infl_weights\n",
    "    al_scaled = torch.cat([al_l_scaled, al_f_scaled], dim=1)\n",
    "\n",
    "    all_src = src + msd\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    r = sns.heatmap(al_scaled, cmap='BuPu',cbar=False,xticklabels=all_src,yticklabels=trg)\n",
    "    r.set_yticklabels(r.get_yticklabels(), rotation=0)\n",
    "    r.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = True, labeltop=True)\n",
    "    \n",
    "    if save_file is not None:\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(save_file)\n",
    "        \n",
    "    else:\n",
    "        r.set_title(\"Heatmap: Scaled alignments\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unscaled alignments - GGH model\n",
    "def unscaled_al_ggh_heatmap(attn_data,ind, fused_msd=False, \n",
    "                            bpe=False, bpe_data=None,n_global_heads=None,save_file=None):\n",
    "    # input data\n",
    "    src = attn_data[ind]['src']\n",
    "    trg = attn_data[ind]['pred']\n",
    "    msd = attn_data[ind]['inflection']\n",
    "    gate_v = attn_data[ind]['attn']['gate']\n",
    "    l_v = attn_data[ind]['attn']['lemma']\n",
    "    f_v = attn_data[ind]['attn']['inflection']\n",
    "    \n",
    "    if not n_global_heads:\n",
    "        l_g_v = attn_data[ind]['attn']['gate_lemma_global']\n",
    "    else:\n",
    "        l_g_v = []\n",
    "        for n in range(n_global_heads):\n",
    "            att_key = 'gate_lemma_global_'+str(n)\n",
    "            l_g_v.append(attn_data[ind]['attn'][att_key])\n",
    "        l_g_v = torch.cat(l_g_v, dim=0)\n",
    "    if bpe:\n",
    "        all_al=torch.cat((l_v,gate_v,f_v), dim=1)\n",
    "    else:\n",
    "        all_al=torch.cat((l_v,gate_v,f_v), dim=1)\n",
    "    \n",
    "        n_cols = all_al.size()[1]\n",
    "        zero_pad = torch.zeros(1,n_cols-l_g_v.size()[1])\n",
    "        l_g_v_pad = torch.cat((l_g_v,zero_pad), dim=1)\n",
    "        all_al = torch.cat((l_g_v_pad,all_al),dim=0)\n",
    "                          \n",
    "\n",
    "    #all_al=torch.cat((l_v,l_g_v,gate_v,f_g_v,f_v), dim=1)\n",
    "    if fused_msd:\n",
    "        all_src = src + ['g_l', 'g_msd'] + msd + ['msd']\n",
    "    else:\n",
    "        all_src = src + ['g_l', 'g_msd'] + msd\n",
    "        \n",
    "    if bpe:\n",
    "        all_trg = trg\n",
    "    else:\n",
    "        all_trg = ['ggh']+trg\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    r = sns.heatmap(all_al, cmap='BuPu',cbar=False,xticklabels=all_src,yticklabels=all_trg)\n",
    "    r.set_yticklabels(r.get_yticklabels(), rotation=0)\n",
    "    r.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = True, labeltop=True)\n",
    "    r.set_title(\"Heatmap: Unscaled alignments and gate\")\n",
    "    \n",
    "    if bpe:\n",
    "        bpe_src = open(bpe_data).readlines()[ind].strip().split('|')\n",
    "        if not n_global_heads:\n",
    "            y_labels = ['ggh']\n",
    "        else:\n",
    "            y_labels = ['ggh_'+str(n) for n in range(n_global_heads)]\n",
    "            \n",
    "        fig = plt.figure(figsize=(3,3))\n",
    "        r = sns.heatmap(l_g_v, cmap='BuPu',cbar=False,xticklabels=bpe_src,yticklabels=y_labels)\n",
    "        r.set_yticklabels(r.get_yticklabels(), rotation=0)\n",
    "        r.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = True, labeltop=True)\n",
    "        r.set_title(\"Heatmap: Gate global alignments\")\n",
    "    return\n",
    "\n",
    "# unscaled alignments scaled with gate  - GGH model\n",
    "def scaled_al_ggh_heatmap(attn_data,ind, fused_msd=False, \n",
    "                          bpe=False, bpe_data=None,n_global_heads=None, mixed=False,save_file=None):\n",
    "    # input data\n",
    "    src = attn_data[ind]['src']\n",
    "    trg = attn_data[ind]['pred']\n",
    "    msd = attn_data[ind]['inflection']\n",
    "    gate_v = attn_data[ind]['attn']['gate']\n",
    "    l_v = attn_data[ind]['attn']['lemma']\n",
    "    f_v = attn_data[ind]['attn']['inflection']\n",
    "    \n",
    "    lemma_weights = gate_v[:, 0].unsqueeze(1)\n",
    "    infl_weights = gate_v[:, 1].unsqueeze(1)\n",
    "\n",
    "    al_l_scaled = l_v * lemma_weights\n",
    "    al_f_scaled = f_v * infl_weights\n",
    "    \n",
    "    if not n_global_heads:\n",
    "        l_g_v = attn_data[ind]['attn']['gate_lemma_global']\n",
    "    else:\n",
    "        if not mixed:\n",
    "            l_g_v = []\n",
    "            for n in range(n_global_heads):\n",
    "                att_key = 'gate_lemma_global_'+str(n)\n",
    "                l_g_v.append(attn_data[ind]['attn'][att_key])\n",
    "            l_g_v = torch.cat(l_g_v, dim=0)\n",
    "        else:\n",
    "            l_g_v_subw = []\n",
    "            l_g_v_char = []\n",
    "            for n in range(n_global_heads):\n",
    "                att_key = 'gate_lemma_subw_global_'+str(n)\n",
    "                l_g_v_subw.append(attn_data[ind]['attn'][att_key])\n",
    "                att_key = 'gate_lemma_char_global_'+str(n)\n",
    "                l_g_v_char.append(attn_data[ind]['attn'][att_key])\n",
    "            l_g_v_subw = torch.cat(l_g_v_subw, dim=0)\n",
    "            l_g_v_char = torch.cat(l_g_v_char, dim=0)\n",
    "    \n",
    "    if bpe:\n",
    "        all_al=torch.cat((al_l_scaled,al_f_scaled), dim=1)\n",
    "    else:\n",
    "        all_al=torch.cat((al_l_scaled,al_f_scaled), dim=1)\n",
    "        n_cols = all_al.size()[1]\n",
    "        zero_pad = torch.zeros(1,n_cols-l_g_v.size()[1])\n",
    "        l_g_v_pad = torch.cat((l_g_v,zero_pad), dim=1)\n",
    "        all_al = torch.cat((l_g_v_pad,all_al),dim=0)\n",
    " \n",
    "    #al_scaled = torch.cat([al_l_scaled, l_g_v,f_g_v, al_f_scaled], dim=1)\n",
    "\n",
    "    if fused_msd:\n",
    "        all_src = src + msd + ['msd']\n",
    "    else:\n",
    "        all_src = src + msd\n",
    "    if bpe:\n",
    "        all_trg=trg\n",
    "    else:\n",
    "        all_trg = ['ggh']+trg\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    r = sns.heatmap(all_al, cmap='BuPu',cbar=False,xticklabels=all_src,yticklabels=all_trg)\n",
    "    r.set_yticklabels(r.get_yticklabels(), rotation=0)\n",
    "    r.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = True, labeltop=True)\n",
    "    if save_file is not None:\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(save_file+'.ch-al'+'.png')\n",
    "    else:\n",
    "        r.set_title(\"Heatmap: Scaled alignments\")\n",
    "    \n",
    "    if bpe:\n",
    "        bpe_src = open(bpe_data).readlines()[ind].strip().split('|')\n",
    "        if not mixed:           \n",
    "            if not n_global_heads:\n",
    "                y_labels = ['ggh']\n",
    "            else:\n",
    "                y_labels = ['ggh_'+str(n) for n in range(n_global_heads)]\n",
    "            fig = plt.figure(figsize=(3,1))\n",
    "            r = sns.heatmap(l_g_v, cmap='BuPu',cbar=False,xticklabels=bpe_src,yticklabels=y_labels)\n",
    "            r.set_yticklabels(r.get_yticklabels(), rotation=0)\n",
    "            r.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = True, labeltop=True)\n",
    "            if save_file is not None:\n",
    "                plt.tight_layout()\n",
    "                fig.savefig(save_file+'.sub-al'+'.png')\n",
    "            else:\n",
    "                r.set_title(\"Heatmap: Gate global alignments\")\n",
    "        else:\n",
    "            y_labels = ['ggh_'+str(n) for n in range(n_global_heads)]\n",
    "            # subwords\n",
    "            \n",
    "            fig = plt.figure(figsize=(3,1))\n",
    "            r = sns.heatmap(l_g_v_subw, cmap='BuPu',cbar=False,xticklabels=bpe_src,yticklabels=y_labels)\n",
    "            r.set_yticklabels(r.get_yticklabels(), rotation=0)\n",
    "            r.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = True, labeltop=True)\n",
    "            if save_file is not None:\n",
    "                plt.tight_layout()\n",
    "                fig.savefig(save_file+'.sub-al'+'.png')\n",
    "            else:\n",
    "                r.set_title(\"Heatmap: Gate global alignments\")\n",
    "            \n",
    "            # chars\n",
    "            fig = plt.figure(figsize=(3,1))\n",
    "            r = sns.heatmap(l_g_v_char, cmap='BuPu',cbar=False,xticklabels=src,yticklabels=y_labels)\n",
    "            r.set_yticklabels(r.get_yticklabels(), rotation=0)\n",
    "            r.tick_params(axis='both', which='major', labelsize=10, labelbottom = False, bottom=False, top = True, labeltop=True)\n",
    "            if save_file is not None:\n",
    "                plt.tight_layout()\n",
    "                fig.savefig(save_file+'.sub-al'+'.png')\n",
    "            else:\n",
    "                r.set_title(\"Heatmap: Gate global alignments\")\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex2pattern(src,trg,msd,al_ind):\n",
    "    # 1. collect type of operations per src_pos (if lemma involved) or msd_pos (only msd is onvolved)\n",
    "    src_op_map={} \n",
    "    msd_op_map={}\n",
    "    # go over inflected form\n",
    "    for i_trg,ch_trg in enumerate(trg[:-1]):\n",
    "        # select salient al-t at pos i_trg:\n",
    "        al_src, al_msd = al_ind[i_trg]\n",
    "        #al_src = al_src.item()\n",
    "        #al_msd = al_msd.item()\n",
    "        # check operation type\n",
    "        if src[al_src]==trg[i_trg]: # copy operation\n",
    "            if al_src!=-1:\n",
    "                al = ((al_src,al_msd), i_trg)\n",
    "                # if aligned to lemma char (plus, possible, msd), save to src_op_map\n",
    "                if al_src not in src_op_map:\n",
    "                    src_op_map[al_src]={'c':[], 'g':[]}\n",
    "                src_op_map[al_src]['c'].append(al)\n",
    "            else:\n",
    "                al = (al_msd, i_trg)\n",
    "                # align to msd\n",
    "                if al_msd not in msd_op_map:\n",
    "                    msd_op_map[al_msd]=[]\n",
    "                msd_op_map[al_msd].append(al)\n",
    "        else:\n",
    "            if al_src!=-1:\n",
    "                al = ((al_src,al_msd), i_trg)\n",
    "                # if aligned to lemma char (plus, possible, msd), save to src_op_map\n",
    "                if al_src not in src_op_map:\n",
    "                    src_op_map[al_src]={'c':[], 'g':[]}\n",
    "                src_op_map[al_src]['g'].append(al)\n",
    "            else:\n",
    "                # align to msd\n",
    "                al = (al_msd, i_trg)\n",
    "                if al_msd not in msd_op_map:\n",
    "                    msd_op_map[al_msd]=[]\n",
    "                msd_op_map[al_msd].append(al)\n",
    "            \n",
    "    # 2. index operations and map src and trg positions to masks \n",
    "    c_ind = 0\n",
    "    g_ind = 0\n",
    "    prev_c_trg=-2 # target position of last copy operation\n",
    "    prev_c_src=-2 # lemma alignment of last copy operation\n",
    "    prev_c_f=-2 # msd alignment of last copy operation\n",
    "    prev_g_trg=-2 # target position of last generation operation\n",
    "    prev_g_src=-2 # alignment of last generation operation\n",
    "    prev_g_f=-2 # msd alignment of last generation operation\n",
    "\n",
    "    src_map = {}\n",
    "    trg_map = {}\n",
    "\n",
    "    def masks(op_ind, op, al_msd):\n",
    "        mask = op+str(op_ind)\n",
    "        if al_msd==-1:\n",
    "            return mask, mask\n",
    "        else:\n",
    "            return mask, '{'+mask+'f'+str(al_msd)+'}'\n",
    "\n",
    "    # go over lemma\n",
    "    for pos in range(len(src)):\n",
    "        if pos in src_op_map:\n",
    "            # check for 1-1 copy\n",
    "            if len(src_op_map[pos]['c'])==1 and len(src_op_map[pos]['g'])==0:\n",
    "                (al_src,al_msd), i_trg = src_op_map[pos]['c'][0]\n",
    "                # adjacent copy?\n",
    "                if prev_c_trg+1==i_trg and prev_c_src+1==al_src and prev_c_f==al_msd:\n",
    "                    prev_c_trg+=1\n",
    "                    prev_c_src+=1\n",
    "                else:\n",
    "                    c_ind+=1\n",
    "                    prev_c_trg=i_trg\n",
    "                    prev_c_src =al_src\n",
    "                    prev_c_f=al_msd  \n",
    "                src_mask, trg_mask = masks(c_ind, 'c', al_msd)\n",
    "                src_map[al_src]=src_mask\n",
    "                trg_map[i_trg]=trg_mask\n",
    "            else:\n",
    "                # index copy operations\n",
    "                if len(src_op_map[pos]['c'])==0:\n",
    "                    src_copy_mask=''\n",
    "                else:\n",
    "                    src_comb_ind=[]\n",
    "                    for (al_src,al_msd), i_trg in src_op_map[pos]['c']:\n",
    "                        c_ind+=1\n",
    "                        _, trg_mask = masks(c_ind, 'c', al_msd)\n",
    "                        trg_map[i_trg]=trg_mask\n",
    "                        src_comb_ind.append(str(c_ind))\n",
    "                    src_copy_mask = 'c'+';'.join(src_comb_ind)\n",
    "                # index generation operation\n",
    "                if len(src_op_map[pos]['g'])==0:\n",
    "                    src_gen_mask=''\n",
    "                else:\n",
    "                    src_comb_ind=[]\n",
    "                    for (al_src,al_msd), i_trg in src_op_map[pos]['g']:\n",
    "                        # adjacent 1-to-many generation?\n",
    "                        if prev_g_trg+1==i_trg and prev_g_src==al_src and prev_g_f==al_msd:\n",
    "                            prev_g_trg+=1\n",
    "                        else:\n",
    "                            g_ind+=1\n",
    "                            prev_g_trg=i_trg\n",
    "                            prev_g_src=al_src\n",
    "                            prev_g_f=al_msd\n",
    "                        \n",
    "                        _, trg_mask = masks(g_ind, 'g', al_msd)\n",
    "                        trg_map[i_trg]=trg_mask\n",
    "                        src_comb_ind.append(str(g_ind)) \n",
    "                    src_gen_mask = 'g'+';'.join(src_comb_ind)\n",
    "                src_map[al_src]=src_copy_mask+src_gen_mask \n",
    "                if len(src_gen_mask)>0 and len(src_copy_mask)>0:\n",
    "                    src_map[al_src]='{'+ src_map[al_src]+'}'\n",
    "                        \n",
    "    # go over MSD and index generation operations aligned to MSD only\n",
    "    f_ind={}\n",
    "    f_prev_trg={}\n",
    "    for pos in range(len(msd)):\n",
    "        if pos in msd_op_map:\n",
    "            for al_msd,i_trg in msd_op_map[pos]:\n",
    "                if al_msd not in f_prev_trg:\n",
    "                    f_prev_trg[al_msd]=i_trg\n",
    "                    f_ind[al_msd]=0\n",
    "                else:\n",
    "                    if i_trg!=f_prev_trg[al_msd]+1:\n",
    "                        f_ind[al_msd]+=1\n",
    "                f_prev_trg[al_msd]=i_trg\n",
    "                trg_mask='f'+str(al_msd)+'_'+str(f_ind[al_msd])\n",
    "                trg_map[i_trg]=trg_mask\n",
    "            \n",
    "            \n",
    "    # mask src and target, group adjacent 1-to-1 copy and 1-to-many generations\n",
    "    mask2src={}\n",
    "    src_pat=[]\n",
    "    for pos in range(len(src)):\n",
    "        if pos in src_map:\n",
    "            mask = src_map[pos]\n",
    "            if len(src_pat)!=0 and src_pat[-1]==mask:\n",
    "                mask2src[mask]+=src[pos]\n",
    "            else:\n",
    "                mask2src[mask]=src[pos]\n",
    "                src_pat.append(mask)\n",
    "        else:\n",
    "            src_pat.append(src[pos])\n",
    "    #src_pat = ' '.join(src_pat)\n",
    "\n",
    "    mask2trg ={}\n",
    "    trg_pat=[]\n",
    "    for pos in range(len(trg[:-1])):\n",
    "        mask = trg_map[pos]\n",
    "        if len(trg_pat)!=0 and trg_pat[-1]==mask:\n",
    "            mask2trg[mask]+=trg[pos]\n",
    "        else:\n",
    "            trg_pat.append(mask)\n",
    "            mask2trg[mask]=trg[pos]\n",
    "    #trg_pat = ' '.join(trg_pat)\n",
    "    \n",
    "    return src_pat, trg_pat, mask2src, mask2trg, trg_map, src_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2patterns(data, allow_double_al=True):\n",
    "    '''\n",
    "    Data is data from torch with fileds:'src', 'pred', 'inflection', 'attn'\n",
    "    'src': ['н', 'а', 'с', 'ы', 'л', 'а', 'т', 'ь'],\n",
    "    'pred': ['н', 'а', 'с', 'ы', 'л', 'а', 'в', 'ш', 'и', 'й', '</s>']\n",
    "    'attn' - has thre fields 'gate', 'lemma', 'inflection' containing sparsemax layers\n",
    "    \n",
    "    Returns list of patterns, each pattern has fields:\n",
    "    al_pat - masked pattern with fused output char with the same als \n",
    "                #'c1 т ь --> c1 в ш ий </s>'\n",
    "    al_list - list of salient non-copy alignemnts \n",
    "                # [('ACT', 'в'), ('PST', 'ш'), ('ACT', 'ий'), ('ь', '</s>')]\n",
    "    copy_al_list - list of copy alignments for chars which also participate \n",
    "                in copy operations (not masked) #(pos,';'-sep. copy_indexes of copied chunks)\n",
    "    src_copy - map from copy_index mask to chars in src \n",
    "    trg_copy - map from copy_index mask to chars in trg #{'c1': 'насыла'}\n",
    "    '''\n",
    "    pattern_list=[]\n",
    "    for i,example in enumerate(data):\n",
    "        # input data\n",
    "        src = example['src']\n",
    "        trg = example['pred']\n",
    "        msd = example['inflection']\n",
    "        gate_v = example['attn']['gate']\n",
    "        l_v = example['attn']['lemma']\n",
    "        f_v = example['attn']['inflection']\n",
    "        \n",
    "        if allow_double_al:\n",
    "            # find the most salient attention in lemma and msd\n",
    "            l_ind = torch.unsqueeze(torch.max(l_v, 1).indices, 1)\n",
    "            f_ind = torch.unsqueeze(torch.max(f_v, 1).indices, 1)\n",
    "            # combine\n",
    "            both_ind = torch.cat((l_ind,f_ind), dim=1)\n",
    "            # select indexes for alignment if gate is more than >0.4 (allow for both gates when their value in 0.4-0.6)\n",
    "            neg_ind = torch.full_like(both_ind, fill_value=-1)\n",
    "            al_ind = torch.where(gate_v>0,both_ind,neg_ind)\n",
    "            #ex2pattern expects al_ind as list of tuples\n",
    "            al_ind = [(al_ind[k,0].item(),al_ind[k,1].item()) for k in range(al_ind.size()[0])]\n",
    "        else:\n",
    "            lemma_weights = gate_v[:, 0].unsqueeze(1)\n",
    "            infl_weights = gate_v[:, 1].unsqueeze(1)\n",
    "\n",
    "            al_l_scaled = l_v * lemma_weights\n",
    "            al_f_scaled = f_v * infl_weights\n",
    "            # find the most salient attention in lemma and msd\n",
    "            l_ind = torch.unsqueeze(torch.max(al_l_scaled, 1).indices, 1)\n",
    "            f_ind = torch.unsqueeze(torch.max(f_v, 1).indices, 1)\n",
    "            \n",
    "            l_max = torch.unsqueeze(torch.max(al_l_scaled, 1).values, 1)\n",
    "            f_max = torch.unsqueeze(torch.max(al_f_scaled, 1).values, 1)\n",
    "            \n",
    "            al_ind=[]\n",
    "            for i_trg in range(len(trg)-1):\n",
    "                if l_max[i_trg]>f_max[i_trg]:\n",
    "                    al_ind.append((l_ind[i_trg].item(), -1))\n",
    "                else:\n",
    "                    al_ind.append((-1, f_ind[i_trg].item()))\n",
    "            \n",
    "        src_pat, trg_pat, mask2src, mask2trg,_,_ = ex2pattern(src,trg,msd,al_ind)\n",
    "        al_pat = ' '.join(src_pat) + ' --> ' + ' '.join(trg_pat)\n",
    "        example_pattern = {'al_pat':al_pat, \n",
    "                           'src_pat':src_pat, \n",
    "                           'trg_pat':trg_pat,\n",
    "                          'mask2src': mask2src,\n",
    "                          'mask2trg': mask2trg}\n",
    "        pattern_list.append(example_pattern)\n",
    "    return pattern_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msd2pattern(partial_MSD,attn_data,pattern_list,gold_files):\n",
    "    ''' average patterns by containg patterns with freq for all data points with MSD containing MSD_phen\n",
    "    returns dict msd: {pattern: masking mappings info}\n",
    "    '''\n",
    "    \n",
    "    gold_lines = []\n",
    "    for f in gold_files:\n",
    "        gold_lines.extend(open(f).readlines())\n",
    "    \n",
    "    phen_dict={}\n",
    "\n",
    "    for i,(example,example_pattern, gold_line) in enumerate(zip(attn_data,pattern_list,gold_lines)):\n",
    "        msd2str = ';'.join(example['inflection'])\n",
    "        _, trg_g, _ = gold_line.strip().split('\\t')\n",
    "        if partial_MSD in msd2str:\n",
    "                if msd2str not in phen_dict:\n",
    "                    phen_dict[msd2str]={}\n",
    "                al_pat = example_pattern['al_pat']\n",
    "                src = ''.join(example['src'])\n",
    "                trg = ''.join(example['pred'][:-1])\n",
    "                if trg == trg_g:\n",
    "                    acc=1\n",
    "                    ex_string = str(i)+' : '+ src +' : ' + trg\n",
    "                else:\n",
    "                    acc=0\n",
    "                    ex_string = str(i)+' : '+ src +' : ' + trg + '(gold: ' + trg_g + ')'\n",
    "                    \n",
    "                if al_pat not in phen_dict[msd2str]:\n",
    "                    phen_dict[msd2str][al_pat] = {'freq':1, 'acc':acc,\n",
    "                                                  'src_pat': example_pattern['src_pat'],\n",
    "                                                  'trg_pat': example_pattern['trg_pat'],\n",
    "                                                 'mask2src':{}, 'mask2trg':{}, \n",
    "                                                  'exs':[ex_string]}\n",
    "                else:\n",
    "                    phen_dict[msd2str][al_pat]['freq']+=1\n",
    "                    phen_dict[msd2str][al_pat]['acc']+=acc\n",
    "                    phen_dict[msd2str][al_pat]['exs'].append(ex_string)\n",
    "                    \n",
    "                # collect frequency of mask,chunk pairs in src\n",
    "                mask2src=example_pattern['mask2src']\n",
    "                for mask, chunk in mask2src.items():\n",
    "                    if mask not in phen_dict[msd2str][al_pat]['mask2src']:\n",
    "                        phen_dict[msd2str][al_pat]['mask2src'][mask] = {}\n",
    "                    if chunk not in phen_dict[msd2str][al_pat]['mask2src'][mask]:\n",
    "                        phen_dict[msd2str][al_pat]['mask2src'][mask][chunk]=1\n",
    "                    else:\n",
    "                        phen_dict[msd2str][al_pat]['mask2src'][mask][chunk]+=1\n",
    "                \n",
    "                # collect frequency of mask,chunk pairs in trg\n",
    "                mask2trg=example_pattern['mask2trg']\n",
    "                for mask, chunk in mask2trg.items():\n",
    "                    if mask not in phen_dict[msd2str][al_pat]['mask2trg']:\n",
    "                        phen_dict[msd2str][al_pat]['mask2trg'][mask] = {}\n",
    "                    if chunk not in phen_dict[msd2str][al_pat]['mask2trg'][mask]:\n",
    "                        phen_dict[msd2str][al_pat]['mask2trg'][mask][chunk]=1\n",
    "                    else:\n",
    "                        phen_dict[msd2str][al_pat]['mask2trg'][mask][chunk]+=1\n",
    "\n",
    "    # unmask singletons in patterns and regroup dictionary by singletons            \n",
    "    phen_dict_regr={}\n",
    "    phen_dict_regr_freq={}\n",
    "    phen_dict_regr_acc={}\n",
    "    #al_pat, al_list, copy_al_list, src_copy, trg_copy\n",
    "    for msd2str in phen_dict:\n",
    "        phen_dict_regr[msd2str]={}\n",
    "        for al_pat in phen_dict[msd2str]:   \n",
    "            #phen_dict[msd2str][al_pat]['unmasked_pat']=al_pat\n",
    "            mask2trg_after_unmasking={}\n",
    "            trg2mask_after_unmasking={}\n",
    "            mask2src_after_unmasking={}\n",
    "            src2mask_after_unmasking={}\n",
    "            #freq = phen_dict[msd2str][al_pat]['freq']\n",
    "            for mask in phen_dict[msd2str][al_pat]['mask2src']:\n",
    "                if len(phen_dict[msd2str][al_pat]['mask2src'][mask].keys())==1:\n",
    "                    chunk = list(phen_dict[msd2str][al_pat]['mask2src'][mask].keys())[0]\n",
    "                    src2mask_after_unmasking[chunk]=mask\n",
    "                else:\n",
    "                    mask2src_after_unmasking[mask]={}\n",
    "                    for chunk,freq in phen_dict[msd2str][al_pat]['mask2src'][mask].items():\n",
    "                        mask2src_after_unmasking[mask][chunk]=freq\n",
    "                    \n",
    "            for mask in phen_dict[msd2str][al_pat]['mask2trg']:\n",
    "                if len(phen_dict[msd2str][al_pat]['mask2trg'][mask].keys())==1:\n",
    "                    chunk = list(phen_dict[msd2str][al_pat]['mask2trg'][mask].keys())[0]\n",
    "                    trg2mask_after_unmasking[chunk]=mask\n",
    "                else:\n",
    "                    mask2trg_after_unmasking[mask]={}\n",
    "                    for chunk,freq in phen_dict[msd2str][al_pat]['mask2trg'][mask].items():\n",
    "                        mask2trg_after_unmasking[mask][chunk]=freq\n",
    "                        \n",
    "            unmasked_src_pat=[]\n",
    "            for mask in phen_dict[msd2str][al_pat]['src_pat']:\n",
    "                if mask in mask2src_after_unmasking:\n",
    "                    unmasked_src_pat.append(mask)\n",
    "                else:\n",
    "                    if mask in phen_dict[msd2str][al_pat]['mask2src']:\n",
    "                        chunk = list(phen_dict[msd2str][al_pat]['mask2src'][mask].keys())[0]\n",
    "                        unmasked_src_pat.append(chunk)\n",
    "                    else:\n",
    "                        # unaligned src chars\n",
    "                        unmasked_src_pat.append(mask)\n",
    "            \n",
    "            unmasked_trg_pat=[]\n",
    "            for mask in phen_dict[msd2str][al_pat]['trg_pat']:\n",
    "                if mask in mask2trg_after_unmasking:\n",
    "                    unmasked_trg_pat.append(mask)\n",
    "                else:\n",
    "                    try:\n",
    "                        chunk = list(phen_dict[msd2str][al_pat]['mask2trg'][mask].keys())[0]\n",
    "                        unmasked_trg_pat.append(chunk)\n",
    "                    except:\n",
    "                        print(phen_dict[msd2str][al_pat]['trg_pat'], mask)\n",
    "                        print(phen_dict[msd2str][al_pat]['mask2trg'])\n",
    "            \n",
    "            unmasked_pat=' '.join(unmasked_src_pat) + ' --> ' + ' '.join(unmasked_trg_pat)\n",
    "            freq = phen_dict[msd2str][al_pat]['freq']\n",
    "            acc = phen_dict[msd2str][al_pat]['acc']\n",
    "            if unmasked_pat not in phen_dict_regr[msd2str]:\n",
    "                phen_dict_regr[msd2str][unmasked_pat]={}\n",
    "                phen_dict_regr[msd2str][unmasked_pat]['freq_by_pat']={}\n",
    "                phen_dict_regr[msd2str][unmasked_pat]['freq']=freq\n",
    "                phen_dict_regr[msd2str][unmasked_pat]['acc']=acc\n",
    "            else:\n",
    "                phen_dict_regr[msd2str][unmasked_pat]['freq']+=freq\n",
    "                phen_dict_regr[msd2str][unmasked_pat]['acc']+=acc\n",
    "                \n",
    "            phen_dict_regr[msd2str][unmasked_pat]['freq_by_pat'][al_pat]=freq\n",
    "            phen_dict_regr[msd2str][unmasked_pat][al_pat]={}\n",
    "            phen_dict_regr[msd2str][unmasked_pat][al_pat]['mask2trg_after_unmasking']=mask2trg_after_unmasking\n",
    "            phen_dict_regr[msd2str][unmasked_pat][al_pat]['trg2mask_after_unmasking']=trg2mask_after_unmasking\n",
    "            phen_dict_regr[msd2str][unmasked_pat][al_pat]['mask2src_after_unmasking']=mask2src_after_unmasking\n",
    "            phen_dict_regr[msd2str][unmasked_pat][al_pat]['src2mask_after_unmasking']=src2mask_after_unmasking\n",
    "            phen_dict_regr[msd2str][unmasked_pat][al_pat]['exs']=phen_dict[msd2str][al_pat]['exs']\n",
    "            \n",
    "            if msd2str not in phen_dict_regr_freq:\n",
    "                phen_dict_regr_freq[msd2str]=freq\n",
    "                phen_dict_regr_acc[msd2str]=acc\n",
    "            else:\n",
    "                phen_dict_regr_freq[msd2str]+=freq\n",
    "                phen_dict_regr_acc[msd2str]+=acc\n",
    "\n",
    "    return phen_dict_regr, phen_dict_regr_freq, phen_dict_regr_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_frequent_patterns(phen_msd, phen_dict_regr, \n",
    "                            phen_dict_regr_freq, phen_dict_regr_acc, n=10, n_class=5):\n",
    "    def print_mask_dict(mask_dict):\n",
    "        for k in ['src2mask_after_unmasking', 'mask2src_after_unmasking', \n",
    "                  'trg2mask_after_unmasking', 'mask2trg_after_unmasking']:\n",
    "            if len(mask_dict[k])!=0:\n",
    "                if k in ['src2mask_after_unmasking','trg2mask_after_unmasking']:\n",
    "                    dict2str = ', '.join('{}:{}'.format(v,m) for v,m in mask_dict[k].items())\n",
    "                    print('\\n___{} (support 1): {}'.format(k,dict2str))\n",
    "                elif k in ['mask2trg_after_unmasking','mask2src_after_unmasking'] :\n",
    "                    items = []\n",
    "                    for m,v in mask_dict[k].items():\n",
    "                        if len(v)<=n_class and not all(f==1 for _,f in mask_dict[k][m].items()):\n",
    "                            dict2str = ', '.join(['{}:{}'.format(s,freq) for s,freq in mask_dict[k][m].items()])\n",
    "                            item_str = '{}: [{}]'.format(m,dict2str)\n",
    "                        else:\n",
    "                            v_lens = [len(s) for s,_ in mask_dict[k][m].items()]\n",
    "                            if all(l==v_lens[0] for l in v_lens):\n",
    "                                item_str = '{}: all of length {}'.format(m,v_lens[0])\n",
    "                            else:\n",
    "                                total_len = 0\n",
    "                                total_freq = 0\n",
    "                                for s,freq in mask_dict[k][m].items():\n",
    "                                    total_len += len(s)*freq\n",
    "                                    total_freq +=freq\n",
    "                                item_str = '{}: average length of {:.1f}'.format(m,total_len/total_freq)\n",
    "                            \n",
    "                        items.append(item_str)\n",
    "                        items2str = '; '.join(items)\n",
    "                    print('\\n___{}: {}'.format(k,items2str))\n",
    "        print('\\nIDs: {}'.format(', '.join(freq_dict[most_freq_pat]['exs'])))\n",
    "                \n",
    "    total_freq = phen_dict_regr_freq[phen_msd]\n",
    "    total_acc = phen_dict_regr_acc[phen_msd]/total_freq\n",
    "    print('MSD {}, frequency: {}, accuracy: {:2f}\\n'.format(phen_msd,total_freq,total_acc))\n",
    "    for unmasked_pat,freq_dict in sorted(phen_dict_regr[phen_msd].items(), key= lambda x:x[1]['freq'], reverse=True)[:n]:\n",
    "        print('frequency: {}, coverage: {}, accuracy: {}'.format(freq_dict['freq'], \n",
    "                                                               freq_dict['freq']/phen_dict_regr_freq[phen_msd],\n",
    "                                                               freq_dict['acc']/freq_dict['freq']))\n",
    "        print('unmasekd_pattern: ', unmasked_pat)\n",
    "        print('frequency by pattern: ', freq_dict['freq_by_pat'])\n",
    "        print('alignments and masks for the most frequent masked pattern:')\n",
    "        most_freq_pat,_ = sorted(freq_dict['freq_by_pat'].items(), key= lambda x:x[1], reverse=True)[0]\n",
    "        print_mask_dict(freq_dict[most_freq_pat])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def msd2decision(partial_MSD,partial_trg,attn_data,gold_files,\n",
    "                 bpe_files,pattern='start',n_global_heads=None,\n",
    "                 pull_max=False, ave_threshold=False, partial_trg_1=None, pattern_1='not_end'):\n",
    "    ''' average patterns by containg patterns with freq for all data points with MSD containing MSD_phen\n",
    "    returns dict msd: {pattern: masking mappings info}\n",
    "    '''\n",
    "    \n",
    "    gold_lines = []\n",
    "    for f in gold_files:\n",
    "        gold_lines.extend(open(f).readlines())\n",
    "        \n",
    "    bpe_lines = []\n",
    "    for f in bpe_files:\n",
    "        bpe_lines.extend(open(f).readlines())\n",
    "    \n",
    "    phen_dict={}\n",
    "    phen_dict['phen'] = {}\n",
    "    phen_dict['rest'] = {}\n",
    "    \n",
    "    phen_dict['phen']['acc'] = 0\n",
    "    phen_dict['phen']['freq'] = 0\n",
    "    phen_dict['phen']['pat'] ={}\n",
    "    \n",
    "    phen_dict['rest']['acc'] = 0\n",
    "    phen_dict['rest']['freq'] = 0\n",
    "    phen_dict['rest']['pat'] ={}\n",
    "    \n",
    "    k=0\n",
    "    for i,(example, gold_line, bpe_line) in enumerate(zip(attn_data,gold_lines,bpe_lines)):\n",
    "        msd2str = ';'.join(example['inflection'])\n",
    "        trg = ''.join(example['pred'][:-1])\n",
    "        _, trg_g, _ = gold_line.strip().split('\\t')\n",
    "        if partial_MSD in msd2str:\n",
    "            k+=1\n",
    "            if (pattern=='end' and trg_g.endswith(partial_trg)) \\\n",
    "            or (pattern=='not_end' and not trg_g.endswith(partial_trg)) \\\n",
    "            or (pattern=='start' and trg_g.startswith(partial_trg)):\n",
    "                if not partial_trg_1 \\\n",
    "                or (pattern_1=='end' and trg_g.endswith(partial_trg_1)) \\\n",
    "                or (pattern_1=='not_end' and not trg_g.endswith(partial_trg_1)) \\\n",
    "                or (pattern_1=='start' and trg_g.startswith(partial_trg_1)):\n",
    "                    fill_dict = 'phen'\n",
    "                else:\n",
    "                    fill_dict = 'rest'\n",
    "            else:\n",
    "                fill_dict = 'rest'\n",
    "            acc = trg == trg_g\n",
    "            phen_dict[fill_dict]['acc'] += acc\n",
    "            phen_dict[fill_dict]['freq'] += 1\n",
    "                \n",
    "            bpe_src = bpe_line.strip().split('|')\n",
    "            al_ind_all = []\n",
    "            for n in range(n_global_heads):\n",
    "                    attn_key = 'gate_lemma_global_' + str(n)\n",
    "                    bpe_al = example['attn'][attn_key]\n",
    "                    #print(bpe_al)\n",
    "                    bpe_al = torch.squeeze(bpe_al, 0) #remove dim 0\n",
    "                    #print(bpe_al_ind)\n",
    "                    if pull_max:\n",
    "                        bpe_al_max_v = torch.max(bpe_al,0).values.item()\n",
    "                        neg_ind = torch.full_like(bpe_al, fill_value=0)\n",
    "                        pos_ind = torch.full_like(bpe_al, fill_value=1)\n",
    "                        al_ind = torch.where(bpe_al==bpe_al_max_v,pos_ind,neg_ind)\n",
    "                        #print(bpe_al_ind)\n",
    "                    elif ave_threshold:\n",
    "                        neg_ind = torch.full_like(bpe_al, fill_value=0)\n",
    "                        pos_ind = torch.full_like(bpe_al, fill_value=1)\n",
    "                        non_zero_al = torch.where(bpe_al>0,pos_ind,neg_ind)\n",
    "                        support = torch.sum(non_zero_al,0).item()\n",
    "                        threshold = 1/support-0.1\n",
    "                        al_ind = torch.where(bpe_al>threshold,pos_ind,neg_ind)\n",
    "                        #if k==1:\n",
    "                        if i==148:\n",
    "                            print('bpe_src',bpe_src)\n",
    "                            print('bpe_al',bpe_al)\n",
    "                            print('non_zero_al',non_zero_al)\n",
    "                            print('support',support)\n",
    "                            print('threshold',threshold)\n",
    "                            print('al_ind',al_ind)\n",
    "                    else:\n",
    "                        neg_ind = torch.full_like(bpe_al, fill_value=0)\n",
    "                        pos_ind = torch.full_like(bpe_al, fill_value=1)\n",
    "                        al_ind = torch.where(bpe_al>0,pos_ind,neg_ind)\n",
    "                    al_ind_all.append(al_ind)\n",
    "            al_ind_all = torch.stack(al_ind_all) # n_global_heads x bpe_src_len\n",
    "            #print(al_ind_all)\n",
    "            \n",
    "            #print(bpe_al_ind)\n",
    "            #print(al_ind)\n",
    "            #print(bpe_src)\n",
    "            #break\n",
    "            pat=[]\n",
    "            for j,bpe in enumerate(bpe_src):\n",
    "                al = al_ind_all[:,j]\n",
    "                if all(a==0 for a in al):\n",
    "                    if len(pat)>0 and pat[-1]=='*':\n",
    "                        pass\n",
    "                    else:\n",
    "                        pat.append('*')\n",
    "                else:\n",
    "                    pat.append(bpe)\n",
    "                    \n",
    "            pat2str = ''.join(pat)\n",
    "            #if acc ==1:\n",
    "            if pat2str not in phen_dict[fill_dict]['pat']:\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]={}\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]['acc'] = acc\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]['freq'] = 1\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]['ex'] = ['{}:{}'.format(i,'|'.join(bpe_src))]\n",
    "            else:\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]['acc'] += acc\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]['freq'] += 1\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]['ex'].append('{}:{}'.format(i,'|'.join(bpe_src)))\n",
    "    return phen_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def msd2decisionMIX(partial_MSD,partial_trg,attn_data,gold_files,\n",
    "                 bpe_files,pattern='start',pull_max=False, ave_threshold=False):\n",
    "    ''' average patterns by containg patterns with freq for all data points with MSD containing MSD_phen\n",
    "    returns dict msd: {pattern: masking mappings info}\n",
    "    '''\n",
    "    \n",
    "    gold_lines = []\n",
    "    for f in gold_files:\n",
    "        gold_lines.extend(open(f).readlines())\n",
    "        \n",
    "    bpe_lines = []\n",
    "    for f in bpe_files:\n",
    "        bpe_lines.extend(open(f).readlines())\n",
    "    \n",
    "    phen_dict={}\n",
    "    phen_dict['phen'] = {}\n",
    "    phen_dict['rest'] = {}\n",
    "    \n",
    "    phen_dict['phen']['acc'] = 0\n",
    "    phen_dict['phen']['freq'] = 0\n",
    "    phen_dict['phen']['pat'] ={}\n",
    "    \n",
    "    phen_dict['rest']['acc'] = 0\n",
    "    phen_dict['rest']['freq'] = 0\n",
    "    phen_dict['rest']['pat'] ={}\n",
    "    \n",
    "    k=0\n",
    "    for i,(example, gold_line, bpe_line) in enumerate(zip(attn_data,gold_lines,bpe_lines)):\n",
    "        msd2str = ';'.join(example['inflection'])\n",
    "        trg = ''.join(example['pred'][:-1])\n",
    "        src, trg_g, _ = gold_line.strip().split('\\t')\n",
    "        if partial_MSD in msd2str:\n",
    "            k+=1\n",
    "            if (pattern=='end' and trg_g.endswith(partial_trg)) or (pattern=='start' and trg_g.startswith(partial_trg)):\n",
    "                fill_dict = 'phen'\n",
    "            else:\n",
    "                fill_dict = 'rest'\n",
    "            acc = trg == trg_g\n",
    "            phen_dict[fill_dict]['acc'] += acc\n",
    "            phen_dict[fill_dict]['freq'] += 1\n",
    "                \n",
    "            bpe_src = bpe_line.strip().split('|')\n",
    "            src = example['src']\n",
    "            \n",
    "            n=0\n",
    "            attn_key_subw = 'gate_lemma_subw_global_' + str(n)\n",
    "            attn_key_char = 'gate_lemma_char_global_' + str(n)\n",
    "            \n",
    "            al_ind_all = []\n",
    "            for attn_key in [attn_key_subw, attn_key_char]:\n",
    "                    al = example['attn'][attn_key]\n",
    "                    al = torch.squeeze(al, 0) #remove dim 0\n",
    "                    if pull_max:\n",
    "                        al_max_v = torch.max(al,0).values.item()\n",
    "                        neg_ind = torch.full_like(al, fill_value=0)\n",
    "                        pos_ind = torch.full_like(al, fill_value=1)\n",
    "                        al_ind = torch.where(al==al_max_v,pos_ind,neg_ind)\n",
    "                        #print(bpe_al_ind)\n",
    "                    elif ave_threshold:\n",
    "                        neg_ind = torch.full_like(al, fill_value=0)\n",
    "                        pos_ind = torch.full_like(al, fill_value=1)\n",
    "                        non_zero_al = torch.where(al>0,pos_ind,neg_ind)\n",
    "                        support = torch.sum(non_zero_al,0).item()\n",
    "                        threshold = 1/support-0.1\n",
    "                        al_ind = torch.where(al>threshold,pos_ind,neg_ind)\n",
    "                        #if k==1:\n",
    "                        #if i==148:\n",
    "                        #    print('bpe_src',bpe_src)\n",
    "                        #    print('bpe_al',bpe_al)\n",
    "                        #    print('non_zero_al',non_zero_al)\n",
    "                        #    print('support',support)\n",
    "                        #    print('threshold',threshold)\n",
    "                        #    print('al_ind',al_ind)\n",
    "                    else:\n",
    "                        neg_ind = torch.full_like(al, fill_value=0)\n",
    "                        pos_ind = torch.full_like(al, fill_value=1)\n",
    "                        al_ind = torch.where(al>0,pos_ind,neg_ind)\n",
    "                    al_ind_all.append(al_ind)\n",
    "            al_ind_subw = al_ind_all[0]\n",
    "            al_ind_char = al_ind_all[1]\n",
    "            #al_ind_all = torch.stack(al_ind_all) # n_global_heads x bpe_src_len\n",
    "            #print(al_ind_all)\n",
    "            \n",
    "            if k==1:\n",
    "                print(bpe_src)\n",
    "                print(example['attn'][attn_key_subw])\n",
    "                print(al_ind_subw)\n",
    "                print(src)\n",
    "                print(example['attn'][attn_key_char])\n",
    "                print(al_ind_char)\n",
    "            #print(al_ind)\n",
    "            #print(bpe_src)\n",
    "            #break\n",
    "            pat=[]\n",
    "            for j,bpe in enumerate(bpe_src):\n",
    "                al = al_ind_subw[j]\n",
    "                if al==0:\n",
    "                    char_ind_start=sum(len(subw)for subw in bpe_src[:j])\n",
    "                    char_ind_end=char_ind_start+len(bpe)\n",
    "                    if k==1:\n",
    "                        print(char_ind_start,char_ind_end)\n",
    "                    for char,al_char in zip(bpe,al_ind_char[char_ind_start:char_ind_end]):\n",
    "                        if al_char==0:\n",
    "                            if len(pat)>0 and pat[-1]=='*':\n",
    "                                pass\n",
    "                            else:\n",
    "                                pat.append('*')\n",
    "                        else:\n",
    "                            pat.append(char)\n",
    "                else:\n",
    "                    pat.append(bpe)\n",
    "            if k==1:\n",
    "                print(pat)\n",
    "            pat2str = ''.join(pat)\n",
    "            if acc ==1:\n",
    "                if pat2str not in phen_dict[fill_dict]['pat']:\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]={}\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]['freq'] = 1\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]['ex'] = ['{}:{}'.format(i,'|'.join(bpe_src))]\n",
    "                else:\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]['freq'] += 1\n",
    "                    phen_dict[fill_dict]['pat'][pat2str]['ex'].append('{}:{}'.format(i,'|'.join(bpe_src)))\n",
    "    return phen_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OBSOLETE\n",
    "#attn sparsemax\n",
    "attn_file='{}/{}/separate-gate-sparse-03-adapt.ymp-{}-models/predict/dev.pred.{}.attn'.format(exp_dir,lang,batch_size, beam_size)\n",
    "\n",
    "attn_data=torch.load(attn_file)\n",
    "\n",
    "scaled_al_heatmap(attn_data,84)\n",
    "scaled_al_heatmap(attn_data,84, save_file='{}/{}/intro-ex-beam4.png'.format(exp_dir,lang))\n",
    "\n",
    "scaled_al_heatmap(attn_data,15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OBSOLETE\n",
    "#attn sparsemax with global gate head, gate is over global(char) head only\n",
    "#attn_file='/mnt/conll/sigm-data/2018/russian/sparsemax-global-gate-head.ymp-models/predict/dev.pred.attn'\n",
    "attn_file='{}/{}/sparsemax-ggh-comb.ymp-{}-models/predict/dev.pred.{}.attn'.format(exp_dir,lang,batch_size,beam_size)\n",
    "\n",
    "attn_ggh_data=torch.load(attn_file)\n",
    "unscaled_al_ggh_heatmap(attn_ggh_data,84,n_global_heads=1)\n",
    "scaled_al_ggh_heatmap(attn_ggh_data,15,n_global_heads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANAAAABACAYAAABrwvk3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEyklEQVR4nO3dX4iUVRzG8e9TiqZWoFealTd2UdkfRSxTiKCIMjGilCKzQsNAijAoKIgoqLwzQVgN/4UhQaEVZaBg/v/TZroJWiCSFZEUmxpK6K+LOcayre64591932meDyw7e3bmfZ8d5uHs7Oyco4jAzHrmkrIDmDUyF8gsgwtklsEFMsvgApllcIHMMrhADUbSa5Lml52jSiRtK+vcLpAVQjWlPJ4iYmIXefr1xbmbtkCSBkv6TNK3ktokTS85z0xJ+1KeVZJGSdqYxjZIuqbMfCnjC+m+apP0fMp4UNJKoA24uqRcJ9LnOyVtlrQOOCDpUkkLJO1O9+MzRZ+7T1paUfcCP0fE/QCSriwriKQbgFeAiRFxTNJQYAWwIiJWSHoKWAhMKzHjOOBJYAIgYCewCRgNPBERO8rK1slY4MaIOCxpDtAeEeMlDQC2SvoyIg4XdbKmnYGA/cDdkt6WNDki2kvMchfwYUQcA4iI34HbgdXp+6uASSVlO2cS8HFEnIyIE8BHwGTgSIXKA7CrQ0HuAWZK2kut8MOoFb4wTTsDRcQhSWOB+4A3JG2IiNfLztWATpYdoJOOeQTMi4j1vXWypp2BJI0A/oqI94EF1Kb+smwEHpY0LGUbCmwDZqTvPwZsLinbOZuBaZIGSRoMPFiBTN1ZD8yV1B9A0nUpe2GadgYCxgALJJ0F/gbmlhUkIr6T9CawSdIZ4BtgHrBM0ovAb9Sef5QmIlolLQd2paGlwB/lJarLUmAU0CpJ1O7HaUWeQH47g1nPNe2vcGZFcIHMMrhAZhlcILMMTV+g9Gp1JVU5G1Q7X19la/oCAZV9EFDtbFDtfC6QWdU15Aupp86cLezFq0WLFxd6vCJVORsUm++RflOLOMy/bmIMUzWlsPtuXXyqrsYb8oXUKj+orGeKLlDRzlcg/wpnlsEFMsvgApllcIHMMrhAZhlcILMMLpBZBhfILIMLZJbBBTLL4AKZZXCBzDK4QGYZCi+QpFmSFl3E9cdJ2i/pB0kL0/pdZg2hCjPQYmA2tTWLR1Nb9N2sIdRVIEmvpm0stkj6QNJ8SePTlhF70xYSbR1uMkLSF5K+l/TOBY47HLgiInZE7Y1JKznPypGS5kjaI2nPe0taLuJHNOs93b4jVdJ44CHgZqA/0Ap8DSwDZkfEdklvdbrZLcCtwGngoKR3I+LHLg5/FXC0w9dH09h/REQL0AJ+Q51VRz0z0B3A2og4FRHHgU/S+OURsT1dXt3pNhsioj0iTgEHgGuLiWtWLb31HOh0h8tnOP9M9xMwssPXI9OYWUOop0BbgQckDZQ0BJiSxo9LmpAuz+j6phcWEb8Af0q6Lf31bSawtifHMitDt8+BImJ32nNyH/ArtZ3d2oGngSVpe5BNaawnngWWA5cBn6cPs4ZQ16o8koZExAlJg4CvqC1adyht9Yekl4DhEfFcr6ZN/EeE/59GXZWn3nXhWiRdDwyktvFtq6Tpkl5OxzgCzCokqVkDqatAEfFoF2NrgDX1nkjSTmBAp+HHI2J/vccwq5o+W5k0IiZ0fy2zxlKFf+Uxa1gukFkGF8gsgwtklsEFMsvgApllcIHMMjTkBltmVeEZyCyDC2SWwQUyy+ACmWVwgcwyuEBmGf4BlqhapR7yTsAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANAAAABACAYAAABrwvk3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEh0lEQVR4nO3dXYhUZRzH8e/PF9KwgjUCS0kCoRd6Q8SVbqK86MKkqCyiFiEUKTCCvUgo8CaIopuStlaiNCokgrRACYyMQst315fWumjJiCIKc4uV2P13MWdrGXfd2XnOes5pfh8Y9syzZ57z3535cc6ZM/M8igjMrDlTii7ArMocILMEDpBZAgfILIEDZJbAATJL4ABlJK2R1FF0HSNJWivphKR3iq7FRidfByovSd8ASyPiVNG1nI8kUXstDRVdSz1JUyNicLL6b9k9kKQOSUckHZb0tqT1kjqLrmuYpNeAa4Dtkp4qup56kuZL6pW0GTgKzCuojg8l7Zd0TNLqrK1f0kuSDgNLJD0i6WtJhyS9LmlqbgVERMvdgBuAk8Dl2f02YD3QWXRtdXV+P1xj2W7AfGAIaC+4jrbs50xqQZ4NBLAia78O+AiYnt1/FejIa/vTcktitdwBvB8RvwJExG+1oxCboL6I2FNwDWsl3ZstzwMWAIPAB1nbncBCYG/2HM8Efslr460aIMvHn0VuXNLtwFJgSUT8JekzYAYwEP+d9wjYFBHrJqOGVj0H+hR4QNJsAEltBddjzbkM+D0Lz7VA+yjr7ATul3QF1J5rSVfnVUBL7oEi4pik54BdkgaBg9TON6xadgBrJJ0AeoFzDicj4rikZ4BPJE0B/gaeAPryKMBvY5slaNVDOLNcOEBmCRwgswQOkFmClg/Q8Mc/yqjMtUG567tQtbV8gIDSvggod21Q7vocILOyq+SF1IHBodwuXm3o6sq1vzyVuTbIt74V05bn0c2/buJGlmtZbv+7bfHxqB+WrOSF1DK/qKw5eQcob2MFyIdwZgkcILMEDpBZAgfILIEDZJbAATJL4ACZJXCAzBI4QGYJHCCzBA6QWQIHyCyBA2SWIPcASVopacME1l8oqUfSd5JelsfYtQopwx6oC1hFbUzjBcBdxZZj1riGAiTp2Wwqiy8kvSepU9KibHqQQ5JelHR0xEOulLRD0reSXjhPv3OASyNiT9S+mLQZuGeMdVdL2idp3xsbuyfwJ5pNnnG/kSppEXAfcDMwHTgA7AfeBFZFxG5Jz9c97BbgVuAs0CvplYj4YZTurwJGTh51Kms7R0R0A93gL9RZeTSyB7oN2BoRAxFxhtpcKwCXRMTubPndusfsjIjTETEAHAdyG8zbrEwm6xzo7IjlQcbe0/0IzB1xf27WZlYJjQToS+BuSTMkzQKWZe1nJC3Olh9qZuMR8RPwh6T27N23DmBrM32ZFWHcc6CI2CtpG3AE+BnoAU4DjwEbJQ0Bu7K2ZjwOvEVt5rDt2c2sEhoalUfSrIjol3Qx8Dm1QetORkR/9vungTkR8eSkVpvxmwj/P1UdlafRceG6JV1Pbfq8TRFxQNKDktZlffQBK3Op1KxCGgpQRDw8StsWYEujG5L0FXBRXfOjEdHTaB9mZXPBRiaNiMXjr2VWLWX4KI9ZZTlAZgkcILMEDpBZAgfILIEDZJbAATJLUMkJtszKwnsgswQOkFkCB8gsgQNklsABMkvgAJkl+AfzfFnC8BWligAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 216x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#attn sparsemax with global gate head, gate is over global(bpe) and local\n",
    "# bpe 1000\n",
    "attn_file='{}/{}/sparsemax-ggh-bpe-comb.ymp-{}-{}-models/predict/dev.pred.{}.attn'.format(exp_dir,lang,bpe_n,batch_size,beam_size)\n",
    "attn_ggh_bpe_data_comb=torch.load(attn_file)\n",
    "bpe_data = '{}/{}/{}-dev-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "scaled_al_ggh_heatmap(attn_ggh_bpe_data_comb,84, bpe=True, bpe_data=bpe_data, n_global_heads=1, save_file='{}/{}/intro-ex-beam4-subs'.format(exp_dir,lang))\n",
    "\n",
    "\n",
    "attn_file='{}/{}/sparsemax-ggh-bpe-comb.ymp-{}-{}-models/predict/train-high.pred.{}.attn'.format(exp_dir,lang,bpe_n,batch_size,beam_size)\n",
    "attn_ggh_bpe_data_comb=torch.load(attn_file)\n",
    "bpe_data = '{}/{}/{}-train-high-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "scaled_al_ggh_heatmap(attn_ggh_bpe_data_comb,7272, bpe=True, bpe_data=bpe_data, n_global_heads=1, save_file='{}/{}/ex7272-train-beam4-subs'.format(exp_dir,lang))\n",
    "\n",
    "#print(attn_ggh_bpe_data_comb[68])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold files\n",
    "gold_file_dev='{}/{}/{}-dev'.format(exp_dir,lang,lang)\n",
    "gold_file_train='{}/{}/{}-train-high'.format(exp_dir,lang,lang)\n",
    "gold_file_test='{}/{}/{}-test'.format(exp_dir,lang,lang)\n",
    "gold_files = [gold_file_dev, gold_file_train, gold_file_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['V;COND;3;SG', 'V;IND;FUT;3;PL', 'V;IND;PST;1;PL;PFV', 'V;IND;PST;1;SG;PFV', 'V;IND;PRS;2;SG', 'V;IND;PRS;3;SG', 'V;SBJV;PRS;3;SG', 'V;IND;PST;3;SG;IPFV', 'V;COND;1;PL', 'V;IND;PST;2;SG;IPFV', 'V;IND;PST;2;PL;IPFV', 'V;POS;IMP;2;SG', 'V;IND;FUT;2;SG', 'V;SBJV;PRS;3;PL', 'V;IND;PST;1;PL;IPFV', 'V;IND;FUT;2;PL', 'V;POS;IMP;3;PL', 'V;NFIN', 'V;IND;PRS;1;PL', 'V;IND;FUT;1;PL', 'V;SBJV;PRS;1;PL', 'V;IND;PST;2;SG;PFV', 'V;POS;IMP;1;PL', 'V;COND;3;PL', 'V;POS;IMP;3;SG', 'V;COND;2;SG', 'V;SBJV;PRS;2;SG', 'V;IND;FUT;1;SG', 'V;SBJV;PST;1;PL', 'V;IND;PST;1;SG;IPFV', 'V;IND;PRS;2;PL', 'V;IND;PRS;1;SG', 'V;SBJV;PST;2;PL', 'V;IND;FUT;3;SG', 'V;COND;1;SG', 'V;SBJV;PST;3;PL', 'V;POS;IMP;2;PL', 'V;IND;PRS;3;PL', 'V;SBJV;PST;2;SG', 'V;IND;PST;2;PL;PFV', 'V;SBJV;PRS;2;PL', 'V;IND;PST;3;PL;PFV', 'V;SBJV;PST;3;SG', 'V;IND;PST;3;PL;IPFV', 'V;IND;PST;3;SG;PFV', 'V;SBJV;PST;1;SG', 'V;SBJV;PRS;1;SG', 'V;COND;2;PL'])\n",
      "MSD V;IND;PRS;3;PL, frequency: 255, accuracy: 0.992157\n",
      "\n",
      "frequency: 149, coverage: 0.5843137254901961, accuracy: 1.0\n",
      "unmasekd_pattern:  c1 a r e --> c1 a n o\n",
      "frequency by pattern:  {'c1 a r e --> c1 f2_0 f3_0 f4_0': 149}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: average length of 6.7\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): a:f2_0, n:f3_0, o:f4_0\n",
      "\n",
      "___mask2trg_after_unmasking: c1: average length of 6.7\n",
      "\n",
      "IDs: 184 : zampicare : zampicano, 316 : crogiolare : crogiolano, 490 : impiombare : impiombano, 491 : sibilare : sibilano, 497 : aureolare : aureolano, 510 : crossare : crossano, 653 : uggiolare : uggiolano, 728 : attovagliare : attovagliano, 836 : ragguagliare : ragguagliano, 861 : attivare : attivano, 881 : cauzionare : cauzionano, 933 : fiancheggiare : fiancheggiano, 1107 : oscillare : oscillano, 1127 : sfiorare : sfiorano, 1174 : ombrare : ombrano, 1231 : ideare : ideano, 1246 : sconfinare : sconfinano, 1303 : ridondare : ridondano, 1409 : satollare : satollano, 1528 : inargentare : inargentano, 1665 : avvezzare : avvezzano, 1750 : abbrusciare : abbrusciano, 1780 : antropizzare : antropizzano, 1837 : stilettare : stilettano, 2020 : confidare : confidano, 2081 : espiare : espiano, 2114 : scristianizzare : scristianizzano, 2177 : azzimare : azzimano, 2188 : sprizzare : sprizzano, 2216 : riabbracciare : riabbracciano, 2290 : smallare : smallano, 2359 : biodegradare : biodegradano, 2418 : zincare : zincano, 2447 : smascellare : smascellano, 2514 : abbadare : abbadano, 2640 : acchiocciolare : acchiocciolano, 2666 : largheggiare : largheggiano, 2673 : insellare : insellano, 2827 : termostatare : termostatano, 2879 : micronizzare : micronizzano, 2975 : arrisicare : arrisicano, 3037 : somministrare : somministrano, 3164 : annasare : annasano, 3251 : stralciare : stralciano, 3286 : sventrare : sventrano, 3296 : disossare : disossano, 3347 : moraleggiare : moraleggiano, 3374 : balenare : balenano, 3434 : ciabattare : ciabattano, 3519 : penare : penano, 3623 : arrossare : arrossano, 3751 : riallungare : riallungano, 3979 : nidificare : nidificano, 3996 : abbozzare : abbozzano, 4131 : innestare : innestano, 4423 : racimolare : racimolano, 4564 : riciclare : riciclano, 4709 : avvantaggiare : avvantaggiano, 4819 : azionare : azionano, 4888 : frangiare : frangiano, 4921 : aviolanciare : aviolanciano, 5070 : tormentare : tormentano, 5148 : clivare : clivano, 5156 : radiocomandare : radiocomandano, 5160 : lacrimare : lacrimano, 5211 : rinfiammare : rinfiammano, 5313 : duramificare : duramificano, 5322 : emendare : emendano, 5397 : traversare : traversano, 5403 : gasare : gasano, 5430 : sgarrare : sgarrano, 5513 : acciaiare : acciaiano, 5682 : lanciare : lanciano, 5825 : spiare : spiano, 5956 : massimizzare : massimizzano, 5965 : vacuolizzare : vacuolizzano, 5968 : azzannare : azzannano, 6004 : noiare : noiano, 6071 : riplasmare : riplasmano, 6216 : cullare : cullano, 6253 : rintasare : rintasano, 6326 : imbullonare : imbullonano, 6494 : ciulare : ciulano, 6650 : quantificare : quantificano, 6674 : solubilizzare : solubilizzano, 6867 : bannare : bannano, 7030 : archeggiare : archeggiano, 7039 : radicaleggiare : radicaleggiano, 7084 : eiettare : eiettano, 7086 : intorbidare : intorbidano, 7134 : sviare : sviano, 7274 : trasformare : trasformano, 7420 : piagare : piagano, 7526 : arcaizzare : arcaizzano, 7547 : denigrare : denigrano, 7579 : intercettare : intercettano, 7706 : rietichettare : rietichettano, 7916 : spezzonare : spezzonano, 8030 : brogliare : brogliano, 8272 : cifrare : cifrano, 8283 : rastrellare : rastrellano, 8315 : monitorare : monitorano, 8374 : pullulare : pullulano, 8401 : arbitrare : arbitrano, 8457 : gelificare : gelificano, 8675 : boicottare : boicottano, 8874 : falciare : falciano, 8893 : quietare : quietano, 8907 : intimare : intimano, 8947 : riabbonare : riabbonano, 9148 : detestare : detestano, 9153 : vendicchiare : vendicchiano, 9528 : frollare : frollano, 9586 : valutare : valutano, 9608 : menstruare : menstruano, 9759 : inchiavardare : inchiavardano, 10041 : immunizzare : immunizzano, 10121 : necrosare : necrosano, 10142 : preparare : preparano, 10261 : ferrare : ferrano, 10325 : sviticchiare : sviticchiano, 10385 : igienizzare : igienizzano, 10401 : mulinare : mulinano, 10507 : proclamare : proclamano, 10619 : spalcare : spalcano, 10671 : impostare : impostano, 10712 : slabbrare : slabbrano, 10867 : ramificare : ramificano, 10919 : menare : menano, 10951 : gramolare : gramolano, 11098 : rasare : rasano, 11169 : rioccupare : rioccupano, 11229 : scalcinare : scalcinano, 11276 : allampanare : allampanano, 11295 : somigliare : somigliano, 11352 : casualizzare : casualizzano, 11353 : affumigare : affumigano, 11382 : cappottare : cappottano, 11463 : vigoreggiare : vigoreggiano, 11464 : allascare : allascano, 11575 : toccare : toccano, 11625 : telegrafare : telegrafano, 11674 : glorificare : glorificano, 11809 : sfigurare : sfigurano, 11822 : ricristallizzare : ricristallizzano, 11843 : stiracchiare : stiracchiano, 11864 : zinnare : zinnano, 11907 : apparigliare : apparigliano, 11937 : significare : significano\n",
      "\n",
      "frequency: 40, coverage: 0.1568627450980392, accuracy: 1.0\n",
      "unmasekd_pattern:  c1 a r s i --> si   c1 a n o\n",
      "frequency by pattern:  {'c1 a r s i --> f0_0 f2_0 c1 f2_1 f3_0 f4_0': 40}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: average length of 6.8\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): si:f0_0,  :f2_0, a:f2_1, n:f3_0, o:f4_0\n",
      "\n",
      "___mask2trg_after_unmasking: c1: average length of 6.8\n",
      "\n",
      "IDs: 232 : impaperarsi : si impaperano, 294 : inguaiarsi : si inguaiano, 607 : destabilizzarsi : si destabilizzano, 701 : lesionarsi : si lesionano, 948 : dilaniarsi : si dilaniano, 1039 : sfarinarsi : si sfarinano, 1122 : schiacciarsi : si schiacciano, 1997 : avviarsi : si avviano, 2044 : surrogarsi : si surrogano, 2251 : circondarsi : si circondano, 2463 : individuarsi : si individuano, 3302 : rimbeccarsi : si rimbeccano, 4003 : impolverarsi : si impolverano, 4297 : aggrondarsi : si aggrondano, 4682 : autodenunciarsi : si autodenunciano, 4862 : approssimarsi : si approssimano, 5702 : incriminarsi : si incriminano, 6149 : discolparsi : si discolpano, 6715 : informarsi : si informano, 7163 : scagionarsi : si scagionano, 7318 : portarsi : si portano, 7337 : giostrarsi : si giostrano, 7418 : situarsi : si situano, 7653 : riputarsi : si riputano, 7732 : collocarsi : si collocano, 7884 : sfiorarsi : si sfiorano, 7968 : prepararsi : si preparano, 8507 : scaldarsi : si scaldano, 8727 : radicarsi : si radicano, 8993 : impantanarsi : si impantanano, 9138 : asfissiarsi : si asfissiano, 9156 : affrancarsi : si affrancano, 9187 : riavviarsi : si riavviano, 9249 : presentarsi : si presentano, 9476 : robotizzarsi : si robotizzano, 10462 : riabilitarsi : si riabilitano, 10581 : sciacquarsi : si sciacquano, 11144 : immedesimarsi : si immedesimano, 11251 : accamparsi : si accampano, 11932 : accordarsi : si accordano\n",
      "\n",
      "frequency: 23, coverage: 0.09019607843137255, accuracy: 1.0\n",
      "unmasekd_pattern:  c1 e r e --> c1 o n o\n",
      "frequency by pattern:  {'c1 e r e --> c1 f1_0 f3_0 f4_0': 23}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: average length of 7.1\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): o:f4_0, n:f3_0\n",
      "\n",
      "___mask2trg_after_unmasking: c1: average length of 7.1\n",
      "\n",
      "IDs: 696 : scontorcere : scontorcono, 1344 : televedere : televedono, 1572 : dispromettere : dispromettono, 1594 : competere : competono, 3169 : perdere : perdono, 3425 : sovrintendere : sovrintendono, 3542 : fraintendere : fraintendono, 3847 : riprendere : riprendono, 3964 : astringere : astringono, 4798 : detorcere : detorcono, 4913 : radioassistere : radioassistono, 5421 : sumere : sumono, 5964 : apprendere : apprendono, 6995 : omettere : omettono, 8184 : ommettere : ommettono, 8616 : svendere : svendono, 8724 : disascondere : disascondono, 8746 : sorprendere : sorprendono, 9862 : adempiere : adempiono, 10716 : profondere : profondono, 11186 : destruggere : destruggono, 11292 : soprascrivere : soprascrivono, 11347 : fremere : fremono\n",
      "\n",
      "frequency: 16, coverage: 0.06274509803921569, accuracy: 1.0\n",
      "unmasekd_pattern:  c1 r e --> c1 s c o n o\n",
      "frequency by pattern:  {'c1 r e --> c1 f3_0 f4_0 f1_0 f3_1 f4_1': 16}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: average length of 7.3\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): s:f3_0, c:f4_0, o:f4_1, n:f3_1\n",
      "\n",
      "___mask2trg_after_unmasking: c1: average length of 7.3\n",
      "\n",
      "IDs: 84 : scolorire : scoloriscono, 576 : accanire : accaniscono, 903 : inzotichire : inzotichiscono, 2662 : arguire : arguiscono, 3397 : incancherire : incancheriscono, 3798 : infarcire : infarciscono, 4714 : circonfluire : circonfluiscono, 5840 : infrollire : infrolliscono, 5979 : smarrire : smarriscono, 6128 : premonire : premoniscono, 6414 : schermire : schermiscono, 7644 : retroagire : retroagiscono, 7778 : imbianchire : imbianchiscono, 10234 : accudire : accudiscono, 10675 : spartire : spartiscono, 10802 : supplire : suppliscono\n",
      "\n",
      "frequency: 7, coverage: 0.027450980392156862, accuracy: 1.0\n",
      "unmasekd_pattern:  c1 r s i --> si   c1 s c o n o\n",
      "frequency by pattern:  {'c1 r s i --> f0_0 f2_0 c1 f3_0 f4_0 f1_0 f3_1 f4_1': 7}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: average length of 7.9\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): si:f0_0,  :f2_0, s:f3_0, c:f4_0, o:f4_1, n:f3_1\n",
      "\n",
      "___mask2trg_after_unmasking: c1: average length of 7.9\n",
      "\n",
      "IDs: 2199 : reinserirsi : si reinseriscono, 4403 : ostruirsi : si ostruiscono, 6042 : inferocirsi : si inferociscono, 8217 : spazientirsi : si spazientiscono, 8928 : invaghirsi : si invaghiscono, 9331 : prostituirsi : si prostituiscono, 11455 : trasferirsi : si trasferiscono\n",
      "\n",
      "frequency: 5, coverage: 0.0196078431372549, accuracy: 1.0\n",
      "unmasekd_pattern:  c1 e r s i --> si   c1 o n o\n",
      "frequency by pattern:  {'c1 e r s i --> f0_0 f2_0 c1 f1_0 f3_0 f4_0': 5}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: average length of 7.0\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): si:f0_0,  :f2_0, o:f4_0, n:f3_0\n",
      "\n",
      "___mask2trg_after_unmasking: c1: average length of 7.0\n",
      "\n",
      "IDs: 2648 : cospargersi : si cospargono, 3762 : proteggersi : si proteggono, 4390 : diffrangersi : si diffrangono, 11832 : raggiungersi : si raggiungono, 11840 : assumersi : si assumono\n",
      "\n",
      "frequency: 2, coverage: 0.00784313725490196, accuracy: 1.0\n",
      "unmasekd_pattern:  c1 g e r e --> c1 g o n o\n",
      "frequency by pattern:  {'c1 g e r e --> c1 f4_0 f1_0 f3_0 f4_1': 2}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: all of length 4\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): g:f4_0, o:f4_1, n:f3_0\n",
      "\n",
      "___mask2trg_after_unmasking: c1: all of length 4\n",
      "\n",
      "IDs: 2716 : scingere : scingono, 4979 : emungere : emungono\n",
      "\n",
      "frequency: 2, coverage: 0.00784313725490196, accuracy: 1.0\n",
      "unmasekd_pattern:  c1 e r e --> c1 g o n o\n",
      "frequency by pattern:  {'c1 e r e --> c1 f4_0 f1_0 f3_0 f4_1': 2}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: all of length 6\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): g:f4_0, o:f4_1, n:f3_0\n",
      "\n",
      "___mask2trg_after_unmasking: c1: all of length 6\n",
      "\n",
      "IDs: 9380 : disvalere : disvalgono, 9454 : pertenere : pertengono\n",
      "\n",
      "frequency: 1, coverage: 0.00392156862745098, accuracy: 1.0\n",
      "unmasekd_pattern:  riotten e r e --> riotten g o n o\n",
      "frequency by pattern:  {'c1 e r e --> c1 f0_0 f1_0 f3_0 f4_0': 1}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___src2mask_after_unmasking (support 1): riotten:c1\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): riotten:c1, g:f0_0, o:f4_0, n:f3_0\n",
      "\n",
      "IDs: 209 : riottenere : riottengono\n",
      "\n",
      "frequency: 1, coverage: 0.00392156862745098, accuracy: 0.0\n",
      "unmasekd_pattern:  riromp e r e --> riromp e n o\n",
      "frequency by pattern:  {'c1 e r e --> c1 f0_0 f3_0 f4_0': 1}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___src2mask_after_unmasking (support 1): riromp:c1\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): riromp:c1, e:f0_0, n:f3_0, o:f4_0\n",
      "\n",
      "IDs: 267 : rirompere : rirompeno(gold: rirompono)\n",
      "\n",
      "frequency: 1, coverage: 0.00392156862745098, accuracy: 1.0\n",
      "unmasekd_pattern:  add a r s i --> si   add an n o\n",
      "frequency by pattern:  {'c1 a r s i --> f0_0 f2_0 c1 f4_0 f3_0 f4_1': 1}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___src2mask_after_unmasking (support 1): add:c1\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): si:f0_0,  :f2_0, add:c1, an:f4_0, n:f3_0, o:f4_1\n",
      "\n",
      "IDs: 1304 : addarsi : si addanno\n",
      "\n",
      "frequency: 1, coverage: 0.00392156862745098, accuracy: 1.0\n",
      "unmasekd_pattern:  sent i r s i --> si   sent o n o\n",
      "frequency by pattern:  {'c1 g1 r s i --> f0_0 f2_0 c1 g1 f3_0 f4_0': 1}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___src2mask_after_unmasking (support 1): sent:c1, i:g1\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): si:f0_0,  :f2_0, sent:c1, o:f4_0, n:f3_0\n",
      "\n",
      "IDs: 1908 : sentirsi : si sentono\n",
      "\n",
      "frequency: 1, coverage: 0.00392156862745098, accuracy: 1.0\n",
      "unmasekd_pattern:  da r s i --> si   da nn o\n",
      "frequency by pattern:  {'c1 r s i --> f0_0 f2_0 c1 f3_0 f4_0': 1}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___src2mask_after_unmasking (support 1): da:c1\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): si:f0_0,  :f2_0, da:c1, nn:f3_0, o:f4_0\n",
      "\n",
      "IDs: 1922 : darsi : si danno\n",
      "\n",
      "frequency: 1, coverage: 0.00392156862745098, accuracy: 1.0\n",
      "unmasekd_pattern:  serv i r e --> serv o n o\n",
      "frequency by pattern:  {'c1 i r e --> c1 f1_0 f3_0 f4_0': 1}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___src2mask_after_unmasking (support 1): serv:c1\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): serv:c1, o:f4_0, n:f3_0\n",
      "\n",
      "IDs: 7525 : servire : servono\n",
      "\n",
      "frequency: 1, coverage: 0.00392156862745098, accuracy: 1.0\n",
      "unmasekd_pattern:  espo r s i --> si   espo n g o n o\n",
      "frequency by pattern:  {'c1 g1 s i --> f0_0 f2_0 c1 g1 f4_0 f1_0 f3_0 f4_1': 1}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___src2mask_after_unmasking (support 1): espo:c1, r:g1\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): si:f0_0,  :f2_0, espo:c1, n:f3_0, g:f4_0, o:f4_1\n",
      "\n",
      "IDs: 7914 : esporsi : si espongono\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#attn sparsemax with global gate head, gate is over global(bpe) and local\n",
    "attn_file_dev='{}/{}/sparsemax-ggh-bpe-comb.ymp-{}-{}-models/predict/dev.pred.{}.attn'.format(exp_dir,lang,bpe_n,batch_size,beam_size)\n",
    "attn_file_train='{}/{}/sparsemax-ggh-bpe-comb.ymp-{}-{}-models/predict/train-high.pred.{}.attn'.format(exp_dir,lang,bpe_n,batch_size,beam_size)\n",
    "attn_file_test='{}/{}/sparsemax-ggh-bpe-comb.ymp-{}-{}-models/predict/test.pred.{}.attn'.format(exp_dir,lang,bpe_n,batch_size,beam_size)\n",
    "\n",
    "attn_files = [attn_file_dev, attn_file_train, attn_file_test]\n",
    "\n",
    "attn_data = []\n",
    "for f in attn_files:\n",
    "    attn_data.extend(torch.load(f))\n",
    "\n",
    "partial_msd='V;'    \n",
    "    \n",
    "pattern_list = data2patterns(attn_data, allow_double_al=False)\n",
    "phen_dict_regr, phen_dict_regr_freq, phen_dict_regr_acc = msd2pattern(partial_msd,\n",
    "                                                                      attn_data,pattern_list,gold_files)\n",
    "print(phen_dict_regr.keys())                                                                      \n",
    "phen_msd = 'V;IND;PRS;3;PL'\n",
    "\n",
    "print_frequent_patterns(phen_msd, phen_dict_regr, \n",
    "                            phen_dict_regr_freq, phen_dict_regr_acc, n=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form ends on scono\n",
      "class:phen, acc: 1.0, freq: 23\n",
      "*re:9/1.0 (903:in|z|o|ti|chi|re), *ire:7/1.0 (84:s|col|or|ire), *ir*:6/1.0 (2199:re|in|ser|ir|si), *cir*:1/1.0 (6042:in|fer|o|cir|si), \n",
      "\n",
      "Form ends on ano\n",
      "class:phen, acc: 1.0, freq: 189\n",
      "*are:149/1.0 (184:z|am|pic|are), *arsi:26/1.0 (232:im|pa|per|arsi), *car*:3/1.0 (3302:ri|mb|ec|car|si), *izzarsi:2/1.0 (607:dest|abil|izz|arsi), *iarsi:2/1.0 (948:di|lan|i|arsi), *par*:2/1.0 (6149:dis|col|par|si), *ciarsi:1/1.0 (4682:au|to|den|un|ci|arsi), *mar*:1/1.0 (6715:in|for|mar|si), *rarsi:1/1.0 (7337:gi|ost|r|arsi), *itarsi:1/1.0 (10462:ri|abil|it|arsi), *quar*:1/1.0 (10581:sci|ac|quar|si), \n",
      "\n",
      "Form ends on ono\n",
      "class:phen, acc: 0.9512195121951219, freq: 41\n",
      "*ere:19/0.9473684210526315 (209:ri|otten|ere), *dere:10/1.0 (1344:te|le|ve|dere), *ger*:3/1.0 (2648:cos|par|ger|si), *re:3/1.0 (7525:servi|re), *e:1/0.0 (267:ri|ro|m|per|e), *ir*:1/1.0 (1908:s|ent|ir|si), *si:1/1.0 (7914:es|p|or|si), *ire:1/1.0 (8706:ri|di|ven|ire), *er*:1/1.0 (11832:r|aggi|ung|er|si), *mer*:1/1.0 (11840:ass|u|mer|si), \n"
     ]
    }
   ],
   "source": [
    "# DECISIONS\n",
    "#attn sparsemax with global gate head, gate is over global(bpe) and local\n",
    "attn_file_dev='{}/{}/sparsemax-ggh-bpe-comb.ymp-{}-{}-models/predict/dev.pred.{}.attn'.format(exp_dir,lang,bpe_n,batch_size,beam_size)\n",
    "attn_file_train='{}/{}/sparsemax-ggh-bpe-comb.ymp-{}-{}-models/predict/train-high.pred.{}.attn'.format(exp_dir,lang,bpe_n,batch_size,beam_size)\n",
    "attn_file_test='{}/{}/sparsemax-ggh-bpe-comb.ymp-{}-{}-models/predict/test.pred.{}.attn'.format(exp_dir,lang,bpe_n,batch_size,beam_size)\n",
    "\n",
    "attn_files = [attn_file_dev, attn_file_train, attn_file_test]\n",
    "\n",
    "attn_data = []\n",
    "for f in attn_files:\n",
    "    attn_data.extend(torch.load(f))\n",
    "\n",
    "#print(attn_data[0])\n",
    "    \n",
    "bpe_file_dev='{}/{}/{}-dev-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "bpe_file_train='{}/{}/{}-train-high-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "bpe_file_test='{}/{}/{}-test-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "\n",
    "\n",
    "bpe_files = [bpe_file_dev, bpe_file_train, bpe_file_test]\n",
    "\n",
    "\n",
    "\n",
    "print('Form ends on scono')\n",
    "partial_trg = 'scono'\n",
    "partial_msd = 'V;IND;PRS;3;PL'\n",
    "\n",
    "phen_dict = msd2decision(partial_msd,partial_trg,attn_data,\n",
    "                         gold_files,bpe_files,pattern='end',\n",
    "                         n_global_heads=1,pull_max=False,ave_threshold=False)\n",
    "for k,v in phen_dict.items():\n",
    "    if k=='phen':\n",
    "        print('class:{}, acc: {}, freq: {}'.format(k,\n",
    "                                               v['acc']/v['freq'], v['freq']))\n",
    "        str_out=''\n",
    "        for p,f in sorted(v['pat'].items(), key=lambda x:x[1]['freq'], reverse=True):\n",
    "            #if f['freq']>10:\n",
    "                #print('{}:{}'.format(p,f['freq']))\n",
    "                #print('({})'.format(', '.join(f['ex'][:10])))\n",
    "                str_out+='{}:{}/{} ({}), '.format(p,f['freq'],f['acc']/f['freq'],f['ex'][0])\n",
    "print(str_out)\n",
    "                \n",
    "print('\\nForm ends on ano')\n",
    "partial_trg = 'ano'\n",
    "partial_msd = 'V;IND;PRS;3;PL'\n",
    "\n",
    "phen_dict = msd2decision(partial_msd,partial_trg,attn_data,\n",
    "                         gold_files,bpe_files,pattern='end',\n",
    "                         n_global_heads=1,pull_max=False,ave_threshold=False)\n",
    "\n",
    "for k,v in phen_dict.items():\n",
    "    if k=='phen':\n",
    "        print('class:{}, acc: {}, freq: {}'.format(k,\n",
    "                                               v['acc']/v['freq'], v['freq']))\n",
    "        str_out=''\n",
    "        for p,f in sorted(v['pat'].items(), key=lambda x:x[1]['freq'], reverse=True):\n",
    "            #if f['freq']>10:\n",
    "                #print('{}:{}'.format(p,f['freq']))\n",
    "                #print('({})'.format(', '.join(f['ex'][:10])))\n",
    "                str_out+='{}:{}/{} ({}), '.format(p,f['freq'],f['acc']/f['freq'],f['ex'][0])\n",
    "print(str_out)\n",
    "                \n",
    "print('\\nForm ends on ono')\n",
    "partial_trg = 'ono'\n",
    "partial_trg_1 = 'scono'\n",
    "partial_msd = 'V;IND;PRS;3;PL'\n",
    "\n",
    "#msd2decision(partial_MSD,partial_trg,attn_data,gold_files,\n",
    "#                 bpe_files,pattern='start',n_global_heads=None,\n",
    "#                 pull_max=False, ave_threshold=False, partial_trg_1=None, pattern_1='not_end')\n",
    "\n",
    "phen_dict = msd2decision(partial_msd,partial_trg,attn_data,\n",
    "                         gold_files,bpe_files,pattern='end',\n",
    "                         n_global_heads=1,pull_max=False,ave_threshold=False,\n",
    "                        partial_trg_1=partial_trg_1, pattern_1='not_end')\n",
    "\n",
    "for k,v in phen_dict.items():\n",
    "    if k=='phen':\n",
    "        print('class:{}, acc: {}, freq: {}'.format(k,\n",
    "                                               v['acc']/v['freq'], v['freq']))\n",
    "        str_out=''\n",
    "        for p,f in sorted(v['pat'].items(), key=lambda x:x[1]['freq'], reverse=True):\n",
    "            #if f['freq']>10:\n",
    "                #print('{}:{}'.format(p,f['freq']))\n",
    "                #print('({})'.format(', '.join(f['ex'][:10])))\n",
    "                str_out+='{}:{}/{} ({}), '.format(p,f['freq'],f['acc']/f['freq'],f['ex'][0])\n",
    "\n",
    "print(str_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form ends on scono\n",
      "class:phen, acc: 1.0, freq: 23\n",
      "*:23/1.0 (84:s|col|or|ire), \n",
      "\n",
      "Form ends on ano\n",
      "class:phen, acc: 1.0, freq: 189\n",
      "*:189/1.0 (184:z|am|pic|are), \n",
      "\n",
      "Form ends on ono\n",
      "class:phen, acc: 0.9512195121951219, freq: 41\n",
      "*:41/0.9512195121951219 (209:ri|otten|ere), \n"
     ]
    }
   ],
   "source": [
    "# DECISIONS\n",
    "#attn sparsemax with global gate head, gate is over global(bpe) and local\n",
    "attn_file_dev='{}/{}/sparsemax-ggh-comb.ymp-{}-models/predict/dev.pred.{}.attn'.format(exp_dir,lang,batch_size,beam_size)\n",
    "attn_file_train='{}/{}/sparsemax-ggh-comb.ymp-{}-models/predict/train-high.pred.{}.attn'.format(exp_dir,lang,batch_size,beam_size)\n",
    "attn_file_test='{}/{}/sparsemax-ggh-comb.ymp-{}-models/predict/test.pred.{}.attn'.format(exp_dir,lang,batch_size,beam_size)\n",
    "\n",
    "attn_files = [attn_file_dev, attn_file_train, attn_file_test]\n",
    "\n",
    "attn_data = []\n",
    "for f in attn_files:\n",
    "    attn_data.extend(torch.load(f))\n",
    "\n",
    "#print(attn_data[0])\n",
    "    \n",
    "bpe_file_dev='{}/{}/{}-dev-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "bpe_file_train='{}/{}/{}-train-high-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "bpe_file_test='{}/{}/{}-test-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "\n",
    "\n",
    "bpe_files = [bpe_file_dev, bpe_file_train, bpe_file_test]\n",
    "\n",
    "\n",
    "\n",
    "print('Form ends on scono')\n",
    "partial_trg = 'scono'\n",
    "partial_msd = 'V;IND;PRS;3;PL'\n",
    "\n",
    "phen_dict = msd2decision(partial_msd,partial_trg,attn_data,\n",
    "                         gold_files,bpe_files,pattern='end',\n",
    "                         n_global_heads=1,pull_max=False,ave_threshold=False)\n",
    "for k,v in phen_dict.items():\n",
    "    if k=='phen':\n",
    "        print('class:{}, acc: {}, freq: {}'.format(k,\n",
    "                                               v['acc']/v['freq'], v['freq']))\n",
    "        str_out=''\n",
    "        for p,f in sorted(v['pat'].items(), key=lambda x:x[1]['freq'], reverse=True):\n",
    "            #if f['freq']>10:\n",
    "                #print('{}:{}'.format(p,f['freq']))\n",
    "                #print('({})'.format(', '.join(f['ex'][:10])))\n",
    "                str_out+='{}:{}/{} ({}), '.format(p,f['freq'],f['acc']/f['freq'],f['ex'][0])\n",
    "print(str_out)\n",
    "                \n",
    "print('\\nForm ends on ano')\n",
    "partial_trg = 'ano'\n",
    "partial_msd = 'V;IND;PRS;3;PL'\n",
    "\n",
    "phen_dict = msd2decision(partial_msd,partial_trg,attn_data,\n",
    "                         gold_files,bpe_files,pattern='end',\n",
    "                         n_global_heads=1,pull_max=False,ave_threshold=False)\n",
    "\n",
    "for k,v in phen_dict.items():\n",
    "    if k=='phen':\n",
    "        print('class:{}, acc: {}, freq: {}'.format(k,\n",
    "                                               v['acc']/v['freq'], v['freq']))\n",
    "        str_out=''\n",
    "        for p,f in sorted(v['pat'].items(), key=lambda x:x[1]['freq'], reverse=True):\n",
    "            #if f['freq']>10:\n",
    "                #print('{}:{}'.format(p,f['freq']))\n",
    "                #print('({})'.format(', '.join(f['ex'][:10])))\n",
    "                str_out+='{}:{}/{} ({}), '.format(p,f['freq'],f['acc']/f['freq'],f['ex'][0])\n",
    "print(str_out)\n",
    "                \n",
    "print('\\nForm ends on ono')\n",
    "partial_trg = 'ono'\n",
    "partial_trg_1 = 'scono'\n",
    "partial_msd = 'V;IND;PRS;3;PL'\n",
    "\n",
    "#msd2decision(partial_MSD,partial_trg,attn_data,gold_files,\n",
    "#                 bpe_files,pattern='start',n_global_heads=None,\n",
    "#                 pull_max=False, ave_threshold=False, partial_trg_1=None, pattern_1='not_end')\n",
    "\n",
    "phen_dict = msd2decision(partial_msd,partial_trg,attn_data,\n",
    "                         gold_files,bpe_files,pattern='end',\n",
    "                         n_global_heads=1,pull_max=False,ave_threshold=False,\n",
    "                        partial_trg_1=partial_trg_1, pattern_1='not_end')\n",
    "\n",
    "for k,v in phen_dict.items():\n",
    "    if k=='phen':\n",
    "        print('class:{}, acc: {}, freq: {}'.format(k,\n",
    "                                               v['acc']/v['freq'], v['freq']))\n",
    "        str_out=''\n",
    "        for p,f in sorted(v['pat'].items(), key=lambda x:x[1]['freq'], reverse=True):\n",
    "            #if f['freq']>10:\n",
    "                #print('{}:{}'.format(p,f['freq']))\n",
    "                #print('({})'.format(', '.join(f['ex'][:10])))\n",
    "                str_out+='{}:{}/{} ({}), '.format(p,f['freq'],f['acc']/f['freq'],f['ex'][0])\n",
    "\n",
    "print(str_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSD V;IND;PRS;3;SG, frequency: 217, accuracy: 0.972350\n",
      "\n",
      "frequency: 124, coverage: 0.5714285714285714, accuracy: 0.9758064516129032\n",
      "unmasekd_pattern:  c1 r e --> c1\n",
      "frequency by pattern:  {'c1 r e --> c1': 124}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: average length of 7.8\n",
      "\n",
      "___mask2trg_after_unmasking: c1: average length of 7.8\n",
      "\n",
      "IDs: 227 : perplimere : perplime, 389 : controllare : controlla, 606 : riproteggere : riprotegge, 708 : spalancare : spalanca, 819 : inzuppare : inzuppa, 820 : sminuzzare : sminuzza, 823 : riscorrere : riscorre, 825 : incazzare : incazza, 929 : agglomerare : agglomera, 941 : strabere : strabe(gold: strabeve), 993 : deionizzare : deionizza, 1101 : confutare : confuta, 1211 : ammodernare : ammoderna, 1367 : prefabbricare : prefabbrica, 1378 : paraffinare : paraffina, 1421 : trasecolare : trasecola, 1468 : armonizzare : armonizza, 1474 : resistere : resiste, 1493 : misturare : mistura, 1540 : personificare : personifica, 1879 : sbrancare : sbranca, 1962 : tonsurare : tonsura, 1980 : correre : corre, 1985 : sbullettare : sbulletta, 2318 : succhiellare : succhiella, 2655 : sforare : sfora, 2681 : suddistinguere : suddistingue, 2904 : trascrivere : trascrive, 2957 : spolettare : spoletta, 3199 : rinfagottare : rinfagotta, 3205 : inquietare : inquieta, 3370 : pacare : paca, 3674 : pimentare : pimenta, 3832 : sfatare : sfata, 3901 : stigmatizzare : stigmatizza, 3919 : cifrare : cifra, 3962 : affamare : affama, 4097 : prepotere : prepote(gold: prepuò), 4144 : incollare : incolla, 4206 : stremare : strema, 4274 : ripiegare : ripiega, 4318 : diffrangere : diffrange, 4402 : tassare : tassa, 4476 : infrascare : infrasca, 4541 : disciogliere : discioglie, 4627 : interpungere : interpunge, 4652 : evolvere : evolve, 4712 : dedicare : dedica, 4739 : ritrascorrere : ritrascorre, 4748 : inghirlandare : inghirlanda, 4816 : margottare : margotta, 4830 : progettare : progetta, 4881 : bombare : bomba, 4962 : blaterare : blatera, 5082 : googlare : googla, 5128 : depingere : depinge, 5180 : tacitare : tacita, 5467 : rimbalzare : rimbalza, 5526 : partizionare : partiziona, 5537 : accedere : accede, 5553 : allineare : allinea, 5657 : rizappare : rizappa, 5729 : orlettare : orletta, 5869 : banalizzare : banalizza, 5909 : riempiere : riempie, 6000 : allampanare : allampana, 6147 : sostentare : sostenta, 6210 : laconizzare : laconizza, 6274 : decuocere : decuoce, 6293 : oscillare : oscilla, 6334 : secretare : secreta, 6351 : continuare : continua, 6449 : ospitare : ospita, 6492 : riabilitare : riabilita, 6652 : bluffare : bluffa, 6653 : discettare : discetta, 6691 : terziarizzare : terziarizza, 6698 : destruggere : destrugge, 6712 : reimpiegare : reimpiega, 6843 : riputare : riputa, 6903 : rassicurare : rassicura, 6952 : evitare : evita, 7368 : ozonizzare : ozonizza, 7375 : addebbiare : addebbia, 7437 : circonfondere : circonfonde, 7479 : rinarrare : rinarra, 7527 : reinsediare : reinsedia, 7824 : pluralizzare : pluralizza, 7828 : addestrare : addestra, 7929 : rifermentare : rifermenta, 7936 : acciottolare : acciottola, 8161 : industrializzare : industrializza, 8286 : innescare : innesca, 8369 : ruminare : rumina, 8370 : pastorizzare : pastorizza, 8413 : ritorcere : ritorce, 8572 : raunare : rauna, 8602 : sbandierare : sbandiera, 8633 : ruzzolare : ruzzola, 8652 : schifare : schifa, 8795 : usurare : usura, 8820 : riconfortare : riconforta, 8984 : rincarnare : rincarna, 9166 : follare : folla, 9168 : reticolare : reticola, 9299 : vincere : vince, 9300 : repellere : repelle, 9477 : sfilare : sfila, 9656 : incerottare : incerotta, 9668 : direggere : diregge, 9682 : soppesare : soppesa, 9775 : infeudare : infeuda, 9997 : tuonare : tuona, 10074 : spigolare : spigola, 10179 : assegnare : assegna, 10346 : discernere : discerne, 10389 : culminare : culmina, 10650 : tepefare : tepefa(gold: tepefà), 11104 : torcere : torce, 11310 : monumentalizzare : monumentalizza, 11417 : rompere : rompe, 11443 : ipotizzare : ipotizza, 11526 : sgomentare : sgomenta, 11801 : ammaestrare : ammaestra\n",
      "\n",
      "frequency: 38, coverage: 0.17511520737327188, accuracy: 1.0\n",
      "unmasekd_pattern:  c1 a r e --> c1 a\n",
      "frequency by pattern:  {'c1 a r e --> c1 f4_0': 38}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: average length of 7.1\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): a:f4_0\n",
      "\n",
      "___mask2trg_after_unmasking: c1: average length of 7.1\n",
      "\n",
      "IDs: 303 : elogiare : elogia, 564 : tediare : tedia, 1295 : mobilitare : mobilita, 1800 : piovigginare : pioviggina, 1865 : fagocitare : fagocita, 1929 : sfalsare : sfalsa, 2507 : incipriare : incipria, 2813 : riattivare : riattiva, 4185 : zampeggiare : zampeggia, 4512 : arruolare : arruola, 4805 : denunziare : denunzia, 5414 : solvatare : solvata, 5611 : rumoreggiare : rumoreggia, 5938 : edificare : edifica, 6040 : teflonare : teflona, 6239 : arrocare : arroca, 6369 : suffragare : suffraga, 6630 : accambiare : accambia, 6718 : mortificare : mortifica, 6810 : cornificare : cornifica, 7673 : someggiare : someggia, 7719 : asciare : ascia, 7783 : foggiare : foggia, 7997 : abbrivare : abbriva, 8043 : beccheggiare : beccheggia, 8324 : albeggiare : albeggia, 9083 : sbertucciare : sbertuccia, 9100 : fiorentineggiare : fiorentineggia, 9196 : trasvolare : trasvola, 9279 : folgoreggiare : folgoreggia, 10250 : scarmigliare : scarmiglia, 10661 : obnubilare : obnubila, 10956 : gelificare : gelifica, 11375 : invogliare : invoglia, 11411 : divincolare : divincola, 11557 : scrosciare : scroscia, 11632 : reincarnare : reincarna, 11851 : impinguare : impingua\n",
      "\n",
      "frequency: 10, coverage: 0.04608294930875576, accuracy: 1.0\n",
      "unmasekd_pattern:  c1 {c2g1} c3 r s i --> s i   c1 c2 c3\n",
      "frequency by pattern:  {'c1 {c2g1} c3 r s i --> f3_0 f1_0 g1 c1 c2 c3': 10}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: [a:6, i:3, u:1]; {c2g1}: [u:1, c:3, n:3, g:2, f:1]; c3: average length of 6.1\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): s:f3_0, i:f1_0,  :g1\n",
      "\n",
      "___mask2trg_after_unmasking: c1: [a:6, i:3, u:1]; c2: [u:1, c:3, n:3, g:2, f:1]; c3: average length of 6.1\n",
      "\n",
      "IDs: 5 : autoeccitarsi : si autoeccita, 597 : accommiatarsi : si accommiata, 1120 : individuarsi : si individua, 2340 : aggiustarsi : si aggiusta, 2799 : innamorarsi : si innamora, 3558 : accollarsi : si accolla, 4912 : aggrondarsi : si aggronda, 5932 : ingozzarsi : si ingozza, 6422 : affrontarsi : si affronta, 6875 : uccidersi : si uccide\n",
      "\n",
      "frequency: 10, coverage: 0.04608294930875576, accuracy: 0.9\n",
      "unmasekd_pattern:  c1 r e --> c1 s ce\n",
      "frequency by pattern:  {'c1 g1 e --> c1 g1 f4_0': 10}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___src2mask_after_unmasking (support 1): r:g1\n",
      "\n",
      "___mask2src_after_unmasking: c1: average length of 7.1\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): s:g1, ce:f4_0\n",
      "\n",
      "___mask2trg_after_unmasking: c1: average length of 7.1\n",
      "\n",
      "IDs: 1148 : guarnire : guarnisce, 2522 : ristabilire : ristabilisce, 4049 : tradire : tradisce, 5779 : inorridire : inorridisce, 6820 : sopire : sopisce, 8338 : bandire : bandisce, 8779 : aggradire : aggradisce, 10556 : approfondire : approfondisce, 10780 : ammannire : ammannisce, 10966 : disconvenire : disconvenisce(gold: disconviene)\n",
      "\n",
      "frequency: 10, coverage: 0.04608294930875576, accuracy: 1.0\n",
      "unmasekd_pattern:  {c1g1} {c2g2} c3 r s i --> s i   c1 c2 c3\n",
      "frequency by pattern:  {'{c1g1} {c2g2} c3 r s i --> f3_0 g2 g1 c1 c2 c3': 10}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: {c1g1}: all of length 1; {c2g2}: [p:2, e:2, o:3, r:2, u:1]; c3: average length of 5.4\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): s:f3_0, i:g2,  :g1\n",
      "\n",
      "___mask2trg_after_unmasking: c1: all of length 1; c2: [p:2, e:2, o:3, r:2, u:1]; c3: average length of 5.4\n",
      "\n",
      "IDs: 1321 : sprofondarsi : si sprofonda, 3338 : levarsi : si leva, 3547 : spalmarsi : si spalma, 3777 : montarsi : si monta, 3984 : voltarsi : si volta, 4494 : coalizzarsi : si coalizza, 5390 : depolimerizzarsi : si depolimerizza, 5450 : cronometrarsi : si cronometra, 9830 : purgarsi : si purga, 11246 : trasformarsi : si trasforma\n",
      "\n",
      "frequency: 9, coverage: 0.041474654377880185, accuracy: 1.0\n",
      "unmasekd_pattern:  {c1g1} c2 r s i --> s i   c1 c2\n",
      "frequency by pattern:  {'{c1g1} c2 r s i --> f3_0 f1_0 g1 c1 c2': 9}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: {c1g1}: [d:2, s:2, c:1, r:3, l:1]; c2: average length of 6.9\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): s:f3_0, i:f1_0,  :g1\n",
      "\n",
      "___mask2trg_after_unmasking: c1: [d:2, s:2, c:1, r:3, l:1]; c2: average length of 6.9\n",
      "\n",
      "IDs: 1126 : diradarsi : si dirada, 1567 : sbloccarsi : si sblocca, 3464 : chiamarsi : si chiama, 5600 : rinforzarsi : si rinforza, 8156 : squilibrarsi : si squilibra, 8225 : dispensarsi : si dispensa, 8355 : lacerarsi : si lacera, 8367 : raggrupparsi : si raggruppa, 9248 : ristabilizzarsi : si ristabilizza\n",
      "\n",
      "frequency: 3, coverage: 0.013824884792626729, accuracy: 1.0\n",
      "unmasekd_pattern:  c1 r e --> c1 sce\n",
      "frequency by pattern:  {'c1 r e --> c1 f4_0': 3}\n",
      "alignments and masks for the most frequent masked pattern:\n",
      "\n",
      "___mask2src_after_unmasking: c1: average length of 6.3\n",
      "\n",
      "___trg2mask_after_unmasking (support 1): sce:f4_0\n",
      "\n",
      "___mask2trg_after_unmasking: c1: average length of 6.3\n",
      "\n",
      "IDs: 1571 : ingerire : ingerisce, 3133 : tripartire : tripartisce, 10373 : svilire : svilisce\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#attn sparsemax with global gate head, gate is over global(bpe), global(char) and local\n",
    "\n",
    "attn_file_dev='{}/{}/sparsemax-ggh-mix-comb.ymp-{}-models/predict/dev.pred.attn'.format(exp_dir,lang,bpe_n)\n",
    "attn_file_train='{}/{}/sparsemax-ggh-mix-comb.ymp-{}-models/predict/train-high.pred.attn'.format(exp_dir,lang,bpe_n)\n",
    "attn_file_test='{}/{}/sparsemax-ggh-mix-comb.ymp-{}-models/predict/test.pred.attn'.format(exp_dir,lang,bpe_n)\n",
    "\n",
    "attn_files = [attn_file_dev, attn_file_train, attn_file_test]\n",
    "\n",
    "attn_data = []\n",
    "for f in attn_files:\n",
    "    attn_data.extend(torch.load(f))\n",
    "\n",
    "partial_msd = 'V;IND;PRS;3;SG'\n",
    "pattern_list = data2patterns(attn_data, allow_double_al=False)\n",
    "phen_dict_regr, phen_dict_regr_freq, phen_dict_regr_acc = msd2pattern(partial_msd,\n",
    "                                                                      attn_data,pattern_list,\n",
    "                                                                      gold_files)\n",
    "\n",
    "phen_msd = 'V;IND;PRS;3;SG'\n",
    "print_frequent_patterns(phen_msd, phen_dict_regr, \n",
    "                            phen_dict_regr_freq, phen_dict_regr_acc, n=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form has a space\n",
      "Form contains um\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9e36dcff71cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'phen'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         print('class:{}, acc: {}, freq: {}'.format(k,\n\u001b[0;32m---> 36\u001b[0;31m                                                v['acc']/v['freq'], v['freq']))\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# DECISIONS\n",
    "#attn sparsemax with global gate head, gate is over global(bpe), global(char) and local\n",
    "# bpe 1000\n",
    "attn_file_dev='{}/{}/sparsemax-ggh-mix-comb.ymp-{}-models/predict/dev.pred.attn'.format(exp_dir,lang,bpe_n)\n",
    "attn_file_train='{}/{}/sparsemax-ggh-mix-comb.ymp-{}-models/predict/train-high.pred.attn'.format(exp_dir,lang,bpe_n)\n",
    "attn_file_test='{}/{}/sparsemax-ggh-mix-comb.ymp-{}-models/predict/test.pred.attn'.format(exp_dir,lang,bpe_n)\n",
    "\n",
    "attn_files = [attn_file_dev, attn_file_train, attn_file_test]\n",
    "\n",
    "attn_data = []\n",
    "for f in attn_files:\n",
    "    attn_data.extend(torch.load(f))\n",
    "\n",
    "#print(attn_data[0])\n",
    "    \n",
    "bpe_file_dev='{}/{}/{}-dev-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "bpe_file_train='{}/{}/{}-train-high-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "bpe_file_test='{}/{}/{}-test-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "\n",
    "bpe_files = [bpe_file_dev, bpe_file_train, bpe_file_test]\n",
    "\n",
    "print('Form has a space')\n",
    "partial_trg = ' '\n",
    "partial_msd = 'V;IND;PRS'\n",
    "\n",
    "print('Form contains um')\n",
    "partial_trg = 'um'\n",
    "partial_msd = 'V;IPFV;AGFOC'\n",
    "\n",
    "phen_dict = msd2decisionMIX(partial_msd,partial_trg,attn_data,\n",
    "                         gold_files,bpe_files,pattern='in',\n",
    "                         pull_max=False,ave_threshold=False)\n",
    "for k,v in phen_dict.items():\n",
    "    if k=='phen':\n",
    "        print('class:{}, acc: {}, freq: {}'.format(k,\n",
    "                                               v['acc']/v['freq'], v['freq']))\n",
    "        for p,f in sorted(v['pat'].items(), key=lambda x:x[1]['freq'], reverse=True):\n",
    "            if f['freq']>=2:\n",
    "                print('{}:{}'.format(p,f['freq']))\n",
    "                print('({})'.format(', '.join(f['ex'][:10])))\n",
    "\n",
    "\n",
    "print('Form start with nag')\n",
    "partial_trg = 'nag-'\n",
    "partial_msd = 'V;IPFV;AGFOC'\n",
    "\n",
    "phen_dict = msd2decision(partial_msd,partial_trg,attn_data,\n",
    "                         gold_files,bpe_files,pattern='start',\n",
    "                         pull_max=False,ave_threshold=False)\n",
    "for k,v in phen_dict.items():\n",
    "    if k=='phen':\n",
    "        print('class:{}, acc: {}, freq: {}'.format(k,\n",
    "                                               v['acc']/v['freq'], v['freq']))\n",
    "        for p,f in sorted(v['pat'].items(), key=lambda x:x[1]['freq'], reverse=True):\n",
    "            if f['freq']>=2:\n",
    "                print('{}:{}'.format(p,f['freq']))\n",
    "                print('({})'.format(', '.join(f['ex'][:10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse double attn\n",
    "attn_file_dev='{}/{}/separate-gate-sparse-03-adapt.ymp-models/predict/dev.pred.attn'.format(exp_dir,lang)\n",
    "attn_file_train='{}/{}/separate-gate-sparse-03-adapt.ymp-models/predict/train-high.pred.attn'.format(exp_dir,lang)\n",
    "attn_file_test='{}/{}/separate-gate-sparse-03-adapt.ymp-models/predict/test.pred.attn'.format(exp_dir,lang)\n",
    "\n",
    "attn_files = [attn_file_dev, attn_file_train, attn_file_test]\n",
    "\n",
    "attn_data = []\n",
    "for f in attn_files:\n",
    "    attn_data.extend(torch.load(f))\n",
    "\n",
    "pattern_list = data2patterns(attn_data, allow_double_al=False)\n",
    "phen_dict_regr, phen_dict_regr_freq, phen_dict_regr_acc = msd2pattern(partial_msd,\n",
    "                                                                      attn_data,pattern_list,\n",
    "                                                                      gold_files)\n",
    "phen_msd = 'V;IND;PRS;3;SG'\n",
    "print_frequent_patterns(phen_msd, phen_dict_regr, \n",
    "                            phen_dict_regr_freq, phen_dict_regr_acc, n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#attn sparsemax with global gate head, gate is over global(bpe), global(char) and local\n",
    "# bpe 1000\n",
    "attn_file='{}/{}/sparsemax-ggh-mix-comb.ymp-{}-models/predict/dev.pred.attn'.format(exp_dir,lang,bpe_n)\n",
    "\n",
    "attn_ggh_bpe_data_comb=torch.load(attn_file)\n",
    "bpe_data = '{}/{}/{}-dev-bpe-{}'.format(exp_dir,lang,lang,bpe_n)\n",
    "\n",
    "scaled_al_ggh_heatmap(attn_ggh_bpe_data_comb,413, bpe=True, bpe_data=bpe_data, n_global_heads=1, mixed=True)\n",
    "scaled_al_ggh_heatmap(attn_ggh_bpe_data_comb,545, bpe=True, bpe_data=bpe_data, n_global_heads=1, mixed=True)\n",
    "scaled_al_ggh_heatmap(attn_ggh_bpe_data_comb,27, bpe=True, bpe_data=bpe_data, n_global_heads=1, mixed=True)\n",
    "\n",
    "#print(attn_ggh_bpe_data_comb[758])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
